<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>research - Goodluck Oguzie</title>
		<link rel="stylesheet" href="dist/reset.css" />
		<link rel="stylesheet" href="dist/reveal.css" />
		<link rel="stylesheet" href="dist/theme/white.css" />
		<link rel="stylesheet" href="plugin/highlight/monokai.css" />

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>

		<link rel="stylesheet" href="mycss.css" />

		<script type="text/javascript">
			window.addEventListener("load", function() {
			  var revealDiv = document.querySelector("body div.reveal");
			  var footer = document.querySelector(".footer");
			  revealDiv.appendChild(footer);
			});
		</script>

		<style>
			.reveal .slide-number {
				font-size: 24pt;
				color: #000000;
			}
			video::-webkit-media-controls-panel {
         		background-image: linear-gradient(transparent, transparent) !important;
    		}
		</style>

	</head>
	<body>
		
		<div class="reveal">
			<div class="slides">
				<!-- =========== TITLE SLIDE (UPDATED BACKGROUND) =========== -->
				<section data-background="img/aston_title_background.jpg" data-background-size="cover" data-background-position="0 20px" style="color: white;">
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 1em;">
						  Enhancing Robot Social Navigation with<br>
						  Reinforcement Learning and Advanced <br>
						        Predictive Models
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						  Goodluck Oguzie
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						  190212683@aston.ac.uk
					</div>
				</section>

				<!-- =========== CONTENT SLIDE (UPDATED, CENTERED, WHITE TEXT, NUMBERED, FIXED BACKGROUND) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="top" data-transition="slide">
					<h2 style="color: white; text-align: center;">Content</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ol style="list-style-position: inside;">
							<li class="fragment">Context and scope:<br><span style="font-size: 0.75em;">Brief introduction to my field of study, goals and objectives of the PhD</span></li>
							<li class="fragment">Reinforcement Learning (RL):<br><span style="font-size: 0.75em;">Introduction to RL and how it enables robots to learn optimal navigation strategies through trial and error</span></li>
							<li class="fragment">Predictive World Models for Social Navigation:<br><span style="font-size: 0.75em;">Use of predictive models to predict future states and improve decision-making in dynamic environments</span></li>
							<li class="fragment">Cosine-Gated LSTM (CGLSTM) for Prediction:<br><span style="font-size: 0.75em;">Development of CGLSTM to improve sequence prediction by integrating cosine-based gating mechanisms</span></li>
							<li class="fragment">Adaptive Prediction Horizons:<br><span style="font-size: 0.75em;">Introduction of an entropy-driven mechanism to dynamically adjust prediction horizons based on environmental uncertainty</span></li>
							<li class="fragment">Conclusion:<br><span style="font-size: 0.75em;">Conclusion of the work done during this 4 years</span></li>
						</ol>
					</div>
					<aside class="notes">
						Briefly outline the structure of your presentation: context, RL, predictive models, technical innovations, adaptive methods, and concluding remarks.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 1 - WHAT IS SOCIAL ROBOT NAVIGATION? (UPDATED BACKGROUND) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">What is Social Robot Navigation?</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Definition: Robots navigating safely in human-populated environments, respecting social norms.</li>
							<li class="fragment">Importance: Critical for seamless integration into daily life, ensuring safety and social acceptance.</li>
							<li class="fragment">Applications: Healthcare robots, hospitality robots, public space navigation.</li>
						</ul>
						<div class="fragment" style="padding-top: 20px;">
							<video muted data-autoplay src="img/socialrobot.mp4" width="70%" controls="controls"></video>
						</div>
					</div>
					<aside class="notes">
						Explain what social robot navigation means, its importance for real-world applications, and how the video illustrates robots interacting with humans.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 2 - CURRENT APPROACHES (UPDATED WITH CLASSICAL.PNG ON RIGHT) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">Current Approaches</h2>
					<div style="display: flex; justify-content: center; align-items: flex-start; padding-top: 100px;">
						<div style="flex: 0 0 50%; text-align: left; font-size: 0.85em; color: white; padding-right: 20px;">
							<ul>
								<li class="fragment">Traditional Methods:
									<ul style="list-style-type: none;">
										<li>Path planning (e.g., A*, Dijkstra’s) for static environments.</li>
										<li>Rule-based systems for human interaction.</li>
									</ul>
								</li>
								<li class="fragment">Modern Approaches:
									<ul style="list-style-type: none;">
										<li>Reinforcement Learning (RL), including advanced methods like Deep RL (e.g., DQN, policy gradient methods) for dynamic environments.</li>
									</ul>
								</li>
							</ul>
						</div>
						<div class="fragment" style="flex: 0 0 50%; text-align: center;">
							<img src="img/classical.PNG" width="100%" style="border: 2px solid white; max-width: 100%; height: auto;" />
						</div>
					</div>
					<aside class="notes">
						Discuss how traditional methods like path planning and rule-based systems work well in static environments but struggle with dynamic, human-populated settings. Highlight modern approaches, particularly RL, as a solution, setting the stage for your research. Mention the image as a visual aid for path planning or navigation methods.
					</aside>
				</section>
			
<!-- ==================================== CONTEXT AND SCOPE: SLIDE 3 - CHALLENGES AND LIMITATIONS =========== -->
			<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
				<h2 style="color: white; text-align: center;">Challenges and Limitations</h2>
				<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
					<ul>
						<li class="fragment">Predicting human behavior in RL and predictive models:
							<ul style="list-style-type: none;">
								<li>Difficulty anticipating sudden movements, group dynamics, and non-verbal cues, limiting RL performance in SocNavGym due to sparse data (Chapter 1, p. 16).</li>
							</ul>
						</li>
						<li class="fragment">Navigating dynamic environments:
							<ul style="list-style-type: none;">
								<li>Complexity of real-world settings with changing obstacles and human interactions, challenging current RL and predictive models’ adaptability and sample efficiency (Chapter 1, p. 16; Chapter 8, p. 151).</li>
							</ul>
						</li>
						<li class="fragment">Balancing efficiency and social norms in current methods:
							<ul style="list-style-type: none;">
								<li>Trade-offs between fast navigation and respecting personal space, cultural norms, and safety, exacerbated by fixed prediction horizons and RL’s computational overhead in dynamic settings (Chapter 1, p. 16; Chapter 8, p. 149, 152).</li>
							</ul>
						</li>
					</ul>
				</div>
				<aside class="notes">
					Explain how these challenges highlight the need for advanced RL and predictive models, referencing your thesis’s focus on addressing unpredictability (e.g., SocNavGym), environmental complexity (e.g., real-world transitions), and efficiency-social compliance trade-offs (e.g., fixed horizon limitations and RL computational challenges in Chapters 1, 8).
				</aside>
			</section>
		<!-- =========== CONTEXT AND SCOPE: SLIDE 4 - RESEARCH QUESTIONS =========== -->
		<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
			<h2 style="color: white; text-align: center; margin-bottom: 20px;">Research Questions</h2>
			<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
				<ul>
					<li class="fragment"><span style="color: #00BFFF;">Q1:</span> How do predictive world models improve decision-making in Social Robot Navigation? (Chapter 1, p. 17)</li>
					<li class="fragment"><span style="color: #00BFFF;">Q2:</span> What challenges arise when transitioning from discrete to continuous action spaces in RL for Social Robot Navigation, and how do we address them? (Chapter 1, p. 17; Chapter 8, p. 149)</li>
				</ul>
			</div>
			<aside class="notes">
				Introduce the two key research questions guiding your thesis, referencing your thesis’s focus on predictive models and RL challenges in continuous action spaces (Chapters 1, 8), and explain how they set the foundation for your objectives and methods.
			</aside>
		</section>
								
		<!-- =========== CONTEXT AND SCOPE: SLIDE 5 - RESEARCH OBJECTIVES =========== -->
		<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
			<h2 style="color: white; text-align: center; margin-bottom: 20px;">Research Objectives</h2>
			<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
				<ul>
					<li class="fragment">Developed RL-based navigation strategies, integrating Soft Actor-Critic (SAC) and DreamerV3, to learn optimal paths through trial and error, improving performance in dynamic SocNavGym and FallingBallEnv environments (Chapter 7, p. 138–143; Chapter 8, p. 149).</li>
					<li class="fragment">Integrated advanced predictive models, including Cosine-Gated LSTM (CGLSTM) and adaptive prediction horizons, achieving up to 30% reduction in Mean Absolute Error (MAE) and a 5% increase in cumulative rewards in SocNavGym and FallingBallEnv (Chapters 6–7, p. 103–114, 138–143; Chapter 8, p. 148).</li>
					<li class="fragment">Evaluated these strategies in simulated environments (SocNavGym, FallingBallEnv, LunarLander-v2), demonstrating a 15% improvement in success rates, computational efficiency (2% increase in inference time), and social compliance in dynamic, human-populated settings (Chapter 7, p. 138–143; Chapter 8, p. 150–151).</li>
				</ul>
			</div>
			<aside class="notes">
				Highlight the specific achievements of your thesis, explaining how you developed RL and predictive models to address social robot navigation challenges, referencing key results (e.g., CGLSTM performance, adaptive horizons) from Chapters 6–8, and setting the stage for your approach details.
			</aside>
		</section>
				

				<!-- =========== ABOUT ME SLIDE =========== -->
				<section data-background="img/aston_background.jpg" data-transition="slide">
					<h3>About Me</h3>
					<div style="text-align: left; font-size: 0.85em;">
						<ul>
							<li class="fragment">Goodluck Oguzie</li>
							<li class="fragment">PhD in Robotics, <a href="https://robolab.unex.es/">Universidad de Extremadura</a>, Cáceres, Spain
								<div class="fragment" style="text-align: center;">
									<img src="img/caceres.jpg" width="70%" style="border: 2px solid white;"/>
								</div>
							</li>
							<li class="fragment">PhD Focus: Robotics, Active Perception, POMDP & Particle Filters</li>
							<li class="fragment">Career: Joined Aston University in August 2018 as Lecturer, now Senior Lecturer</li>
							<li class="fragment">Lab: <a href="https://arp-lab.com">Autonomous Robotics and Perception Lab</a></li>
						</ul>
					</div>
					<aside class="notes">
						Highlight your journey from PhD to current role, and briefly mention how it ties to social navigation research.
					</aside>
				</section>

				<!-- =========== LINES OF RESEARCH SLIDE =========== -->
				<section>
					<h2>Lines of research</h2>
					<ul>
						<li>human pose estimation <b>&</b> monitoring</li>
						<li>monocular depth estimation <b>&</b> traffic understanding</li>
						<li>social navigation</li>
					</ul>
				</section>

				<!-- =========== HUMAN TRACKING AND MONITORING SLIDE =========== -->
				<section>
					<section>
						<h4>Human tracking and monitoring</h4>
						<ul style="font-size: 0.8em; line-height: 1.1;">
							<li>Motivation: experience from previous projects <b>&</b> the need for tracking in Social Robot Navigation</li>
							<li class="fragment">Applicable in real-life conditions</li>
							<li class="fragment">Multi-camera, multi-person, full-skeleton, self-supervised</li>
							<li class="fragment">Project with Legrand Care, £244,512 (January 2024, 30 months).</li>
							<li class="fragment">With PhD students D. Rodriguez-Criado (former), V. Gbouna and PDRA Maria Vicini.</li>
						</ul>
						<span class="fragment">
							<video muted data-autoplay id="video_hpe" src="resources/sevilla2.mp4" width="540px" controls="controls"></video>
							<video data-autoplay id="video_hpe" src="resources/hpe.mp4" width="630px" controls="controls"></video>
						</span>
						<br/>
						<div class="reveal" style="width: 70%; margin-left: auto; margin-right: auto; line-height: 1.06;">
							<span style="font-family: monospace; font-size: 0.45em; text-align: left; display: inline-block;">
								<b style="color: red;">[1]</b> Rodriguez-Criado D, Bachiller-Burgos P, Vogiatzis G, Manso LJ. Multi-person 3D pose estimation from unlabelled data.
								<u>Machine Vision and Applications, Springer</u>. 2024 May;35(3):1-8.
							</span>
						</div>
					</section>

					<section>
						<embed src="pdfs/hpe.pdf" width="90%" height="900px"/>
					</section>
				</section>

				<!-- Continue with remaining sections unchanged... -->

			</div>
		</div>

		<script>
			Reveal.initialize({
				hash: true,
				width: 1600,
				height: 900,
				slideNumber: true,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>

		<!-- <div class="footer">
			<span style="font-size: 0.7em;">https://ljmanso.github.io/r</span>
		</div> -->
	</body>
</html>
