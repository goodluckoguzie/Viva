<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>research - Goodluck Oguzie</title>
		<link rel="stylesheet" href="dist/reset.css" />
		<link rel="stylesheet" href="dist/reveal.css" />
		<link rel="stylesheet" href="dist/theme/white.css" />
		<link rel="stylesheet" href="plugin/highlight/monokai.css" />

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>

		<link rel="stylesheet" href="mycss.css" />

		<script type="text/javascript">
			window.addEventListener("load", function() {
			  var revealDiv = document.querySelector("body div.reveal");
			  var footer = document.querySelector(".footer");
			  revealDiv.appendChild(footer);
			});
		</script>

		<style>
			.reveal .slide-number {
				font-size: 24pt;
				color: #000000;
			}
			video::-webkit-media-controls-panel {
         		background-image: linear-gradient(transparent, transparent) !important;
    		}
			.reveal section div ul li span {
				line-height: 1.2;
			}
			.content-item {
				display: flex;
				align-items: center;
				margin: 10px 0;
			}
			.content-number {
				font-size: 1.5em;
				color: white;
				margin-right: 10px;
				width: 20px;
				text-align: right;
			}
			.content-text {
				flex: 1;
				text-align: left;
			}
			.network-graphic {
				position: absolute;
				bottom: 0;
				left: 0;
				width: 100%;
				height: auto;
				z-index: -1;
			}
		</style>

	</head>
	<body>
		
		<div class="reveal">
			<div class="slides">
				<!-- =========== TITLE SLIDE (UPDATED BACKGROUND) =========== -->
				<section data-background="img/aston_title_background.jpg" data-background-size="cover" data-background-position="0 20px" style="color: white;">
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 1em;">
						  Enhancing Robot Social Navigation with<br>
						  Reinforcement Learning and Advanced <br>
						        Predictive Models
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						  Goodluck Oguzie
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						  190212683@aston.ac.uk
					</div>
				</section>

				<!-- =========== CONTENT SLIDE (UPDATED, CENTERED, WHITE TEXT, NUMBERED CIRCLES, FIXED BACKGROUND, NETWORK GRAPHIC) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="top" data-transition="slide">
					<h2 style="color: white; text-align: center;">Content</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 80px;">
						<ul style="list-style: none; padding: 0;">
							<li class="fragment content-item">
								<span class="content-number">1</span>
								<div class="content-text">Context and Scope: Introduces social robot navigation with clear study goals and objectives of the PhD</div>
							</li>
							<li class="fragment content-item">
								<span class="content-number">2</span>
								<div class="content-text">Social Robot Navigation: Overview, history, and approaches to robot navigation in human-populated settings</div>
							</li>
							<li class="fragment content-item">
								<span class="context-number">3</span>
								<div class="content-text">Reinforcement Learning (RL): Introduction to RL and how it enables robots to learn optimal navigation strategies through trial and error</div>
							</li>
							<li class="fragment content-item">
								<span class="content-number">4</span>
								<div class="content-text">Predictive World Models for Social Navigation: Use of predictive models to predict future states and improve decision-making in dynamic environments</div>
							</li>
							<li class="fragment content-item">
								<span class="content-number">5</span>
								<div class="content-text">Cosine-Gated LSTM (CGLSTM) for Prediction: Development of CGLSTM to improve sequence prediction by integrating cosine-based gating mechanisms</div>
							</li>
							<li class="fragment content-item">
								<span class="content-number">6</span>
								<div class="content-text">Adaptive Prediction Horizons in RL: Introduction of an entropy-driven mechanism to dynamically adjust prediction horizons based on environmental uncertainty</div>
							</li>
							<li class="fragment content-item">
								<span class="content-number">7</span>
								<div class="content-text">Conclusion: Conclusion of the work done during this 4 years</div>
							</li>
						</ul>
						<img src="img/network_graphic.png" class="network-graphic" alt="Network Graphic" />
					</div>
					<aside class="notes">
						Outline the structure of your presentation: context, social navigation, RL fundamentals, predictive models, CGLSTM, adaptive horizons, and conclusion, matching the visual style from the image.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 3 - WHAT IS SOCIAL ROBOT NAVIGATION? (UPDATED BACKGROUND) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">What is Social Robot Navigation?</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Definition: Robots navigating safely in human-populated environments, respecting social norms.</li>
							<li class="fragment">Importance: Critical for seamless integration into daily life, ensuring safety and social acceptance.</li>
							<li class="fragment">Applications: Healthcare robots, hospitality robots, public space navigation.</li>
						</ul>
						<div class="fragment" style="padding-top: 20px;">
							<video muted data-autoplay src="img/socialrobot.mp4" width="70%" controls="controls"></video>
						</div>
					</div>
					<aside class="notes">
						Explain what social robot navigation means, its importance for real-world applications, and how the video illustrates robots interacting with humans.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 4 - CURRENT APPROACHES (UPDATED WITH CLASSICAL.PNG ON RIGHT) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">Current Approaches</h2>
					<div style="display: flex; justify-content: center; align-items: flex-start; padding-top: 100px;">
						<div style="flex: 0 0 50%; text-align: left; font-size: 0.85em; color: white; padding-right: 20px;">
							<ul>
								<li class="fragment">Traditional Methods:
									<ul style="list-style-type: none;">
										<li>Path planning (e.g., A*, Dijkstra’s) for static environments.</li>
										<li>Rule-based systems for human interaction.</li>
									</ul>
								</li>
								<li class="fragment">Modern Approaches:
									<ul style="list-style-type: none;">
										<li>Reinforcement Learning (RL), including advanced methods like Deep RL (e.g., DQN, policy gradient methods) for dynamic environments.</li>
									</ul>
								</li>
							</ul>
						</div>
						<div class="fragment" style="flex: 0 0 50%; text-align: center;">
							<img src="img/classical.PNG" width="100%" style="border: 2px solid white; max-width: 100%; height: auto;" />
						</div>
					</div>
					<aside class="notes">
						Discuss how traditional methods like path planning and rule-based systems work well in static environments but struggle with dynamic, human-populated settings. Highlight modern approaches, particularly RL, as a solution, setting the stage for your research. Mention the image as a visual aid for path planning or navigation methods.
					</aside>
				</section>

				<!-- =========== FOUNDATIONS: SLIDE 5 - SOCIAL ROBOT NAVIGATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Social Robot Navigation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Introduction: Robots navigating in human-populated environments, respecting social norms (Chapter 4, p. 58).</li>
							<li class="fragment">Historical Overview: Evolved from classical path planning to ML-based methods (Chapter 4, p. 58).</li>
							<li class="fragment">Approaches:
								<ul style="list-style-type: none;">
									<li>Classical: Path planning (A*, Dijkstra’s), rule-based systems (Chapter 4, p. 60).</li>
									<li>Machine Learning: RL, predictive models for dynamic settings (Chapter 4, p. 61).</li>
								</ul>
							</li>
							<li class="fragment">SocNavGym: A benchmark environment for testing social navigation (Chapter 4, p. 63).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/social_navigation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Introduce social robot navigation, its history, approaches, and SocNavGym, referencing the diagram illustrating classical vs. ML approaches or SocNavGym layout.
					</aside>
				</section>

				<!-- =========== FOUNDATIONS: SLIDE 6 - REINFORCEMENT LEARNING =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Reinforcement Learning</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Overview: RL enables robots to learn optimal navigation strategies via trial and error, maximizing rewards (Chapter 3, p. 34).</li>
							<li class="fragment">Key Concepts:
								<ul style="list-style-type: none;">
									<li>History: Originated in the 1950s, evolved with dynamic programming (Chapter 3, p. 32).</li>
									<li>RL Problem: Agent learns through trial and error (Chapter 3, p. 34).</li>
									<li>Model-Free (e.g., Q-learning, SAC): Learn from experience (Chapter 3, p. 36).</li>
									<li>Model-Based (e.g., DreamerV3): Use world models (Chapter 3, p. 36).</li>
									<li>Policy Learning: Optimize policies for actions (Chapter 3, p. 39).</li>
								</ul>
							</li>
							<li class="fragment">Algorithms Used: DQN, DDPG, PPO, A2C, SAC, DreamerV3 for social navigation (Chapter 3, p. 40–51).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/rl_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain RL’s core concepts, history, problem, model-free vs. model-based approaches, policy learning, and algorithms, emphasizing their application in social navigation, referencing the diagram illustrating RL frameworks or SocNavGym integration.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 7 - CURRENT STATE OF ART IN RL =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Current State of Art in RL</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">RL Algorithms:
								<ul style="list-style-type: none;">
									<li>Deep Q-Network (DQN): Value-based, discrete actions, limited in continuous navigation (Chapter 3, p. 40).</li>
									<li>Deep Deterministic Policy Gradient (DDPG): Continuous actions, deterministic, struggles with exploration (Chapter 3, p. 42).</li>
									<li>Proximal Policy Optimization (PPO): Stable policy gradient, but computationally intensive (Chapter 3, p. 44).</li>
									<li>Advantage Actor-Critic (A2C): Combines value/policy, less efficient in complex tasks (Chapter 3, p. 46).</li>
									<li>Soft Actor-Critic (SAC): Stochastic, continuous spaces, exploration challenges (Chapter 3, p. 48).</li>
									<li>DreamerV3: Model-based, long-term planning, computationally expensive in dynamic settings (Chapter 3, p. 51).</li>
								</ul>
							</li>
							<li class="fragment">Limitations:
								<ul style="list-style-type: none;">
									<li>Sample efficiency: Requires extensive data, challenging in real-world settings (Chapter 3, p. 54; Chapter 8, p. 151).</li>
									<li>Reliance on simulated environments: Struggles with real-world transitions (Chapter 8, p. 151).</li>
									<li>Fixed prediction horizons: Limits adaptability in dynamic environments (Chapter 5, p. 86).</li>
									<li>Exploration challenges: Particularly in continuous action spaces, affecting long-term planning (Chapter 7, p. 121).</li>
								</ul>
							</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/rl_state_of_art_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Discuss the current state of RL, highlighting algorithms from Chapter 3 and their limitations, setting the stage for your research to address sample efficiency, adaptability, and exploration challenges with CGLSTM and adaptive horizons.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 8 - CHALLENGES AND LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">Challenges and Limitations</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Predicting human behavior in current RL and predictive models:
								<ul style="list-style-type: none;">
									<li>Difficulty anticipating sudden movements, group dynamics, and non-verbal cues, limiting RL performance in SocNavGym due to sparse data and fixed horizons (Chapter 3, p. 54; Chapter 5, p. 86).</li>
								</ul>
							</li>
							<li class="fragment">Navigating dynamic environments:
								<ul style="list-style-type: none;">
									<li>Complexity of real-world settings with changing obstacles and human interactions, challenging RL adaptability, sample efficiency, and predictive model robustness (Chapter 4, p. 61; Chapter 7, p. 121; Chapter 8, p. 151).</li>
								</ul>
							</li>
							<li class="fragment">Balancing efficiency and social norms in current methods:
								<ul style="list-style-type: none;">
									<li>Trade-offs between fast navigation and respecting personal space, cultural norms, and safety, worsened by RL’s computational overhead and fixed prediction horizons (Chapter 4, p. 61; Chapter 5, p. 86; Chapter 7, p. 125).</li>
								</ul>
							</li>
						</ul>
					</div>
					<aside class="notes">
						Explain how these challenges highlight the need for advanced RL and predictive models, referencing your thesis’s focus on addressing unpredictability (e.g., SocNavGym), environmental complexity, and efficiency-social compliance trade-offs (e.g., fixed horizons and RL limitations in Chapters 3–7).
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 9 - RESEARCH QUESTIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Research Questions</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment"><span style="color: #00BFFF;">Q1:</span> How do predictive world models improve decision-making in Social Robot Navigation? (Chapter 1, p. 17)</li>
							<li class="fragment"><span style="color: #00BFFF;">Q2:</span> What challenges arise when transitioning from discrete to continuous action spaces in RL for Social Robot Navigation, and how do we address them? (Chapter 3, p. 42; Chapter 7, p. 121; Chapter 8, p. 149)</li>
						</ul>
						<div class="fragment" style="padding-top: 20px;">
							<img src="img/predictive_model_diagram.jpg" width="70%" style="border: 2px solid white;" />
						</div>
					</div>
					<aside class="notes">
						Introduce the two key research questions guiding your thesis, referencing your thesis’s focus on predictive models and RL challenges in continuous action spaces (Chapters 1, 3, 7, 8). Explain how the diagram illustrates predictive world models or action space transitions, setting the foundation for your objectives and methods.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 10 - RESEARCH OBJECTIVES =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Research Objectives</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Developed RL-based navigation strategies, integrating Soft Actor-Critic (SAC), DreamerV3, DQN, DDPG, PPO, and A2C, to learn optimal paths through trial and error, addressing sample efficiency and exploration challenges in SocNavGym and FallingBallEnv (Chapter 7, p. 138–143; Chapter 8, p. 149).</li>
							<li class="fragment">Integrated advanced predictive models, including Cosine-Gated LSTM (CGLSTM), 2StepAhead, MASPM, and adaptive prediction horizons, achieving up to 30% reduction in Mean Absolute Error (MAE) and a 5% increase in cumulative rewards in SocNavGym and FallingBallEnv, tackling fixed horizon and prediction accuracy limitations (Chapters 5–7, p. 86, 103–114, 138–143; Chapter 8, p. 148).</li>
							<li class="fragment">Evaluated these strategies in simulated environments (SocNavGym, FallingBallEnv, LunarLander-v2), demonstrating a 15% improvement in success rates, computational efficiency (2% increase in inference time), and social compliance, overcoming dynamic environment and efficiency-social norm trade-offs (Chapter 7, p. 138–143; Chapter 8, p. 150–151).</li>
						</ul>
						<div class="fragment" style="padding-top: 20px;">
							<img src="img/rl_predictive_model_diagram.jpg" width="70%" style="border: 2px solid white;" />
						</div>
					</div>
					<aside class="notes">
						Highlight the specific achievements of your thesis, explaining how you developed RL and predictive models to address social robot navigation challenges, referencing key results (e.g., CGLSTM, adaptive horizons) from Chapters 5–8 and the limitations they overcome, setting the stage for methodology details.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 11 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models: Challenges/Limitations</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Fixed Prediction Horizons: 2StepAhead and MASPM limited by inflexibility in dynamic environments, reducing adaptability (Chapter 5, p. 86).</li>
							<li class="fragment">Computational Overhead: MASPM’s multi-agent prediction increases processing demands, impacting efficiency (Chapter 5, p. 84).</li>
							<li class="fragment">Sparse Data: Difficulty predicting human behavior in SocNavGym due to limited training data, affecting accuracy (Chapter 5, p. 87).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of predictive world models, emphasizing fixed horizons, computational overhead, and sparse data issues, referencing the diagram illustrating these in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 12 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models: Methods</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">2StepAhead: Fixed two-step horizon model predicting short-term states for RL integration (Chapter 5, p. 83).</li>
							<li class="fragment">MASPM: Multi-action state prediction model for human-robot interactions, using RL state transitions (Chapter 5, p. 84).</li>
							<li class="fragment">2StepAhead-MASPM: Combined approach enhancing prediction accuracy in SocNavGym (Chapter 5, p. 85).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the methods of 2StepAhead, MASPM, and their combination, referencing the diagram illustrating their integration with RL in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 13 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models: Evaluation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, focusing on dynamic human-robot interactions (Chapter 5, p. 86).</li>
							<li class="fragment">Metrics: Training phase evaluated with MSE, testing phase with MAE and accuracy (Chapter 5, p. 87–88).</li>
							<li class="fragment">Approach: Compared 2StepAhead, MASPM, and 2StepAhead-MASPM for prediction robustness (Chapter 5, p. 86).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of predictive world models in SocNavGym, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 14 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models: Results</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Training Phase: 2StepAhead-MASPM achieved 20% lower MSE than standalone models, improving prediction stability (Chapter 5, p. 87).</li>
							<li class="fragment">Testing Phase: 2StepAhead-MASPM reduced MAE by 15% in SocNavGym, enhancing RL decision-making (Chapter 5, p. 88).</li>
							<li class="fragment">Impact: Improved RL robustness, but limited by fixed horizons (Chapter 5, p. 86).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the results of predictive world models, emphasizing 2StepAhead-MASPM performance and fixed horizon limitations, referencing the diagram showing MSE/MAE improvements in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 15 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Cosine-Gated LSTM (CGLSTM) for Prediction: Challenges/Limitations</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Prediction Accuracy: Traditional LSTMs, GRUs, and RAUs struggle with long-term sequence prediction in dynamic environments (Chapter 6, p. 94).</li>
							<li class="fragment">Sparse Data: Limited training data in SocNavGym affects CGLSTM performance, reducing generalization (Chapter 6, p. 113).</li>
							<li class="fragment">Computational Complexity: Higher processing demands for cosine gating compared to baseline models (Chapter 6, p. 98).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of CGLSTM, emphasizing prediction accuracy, sparse data, and computational complexity, referencing the diagram illustrating these in SocNavGym or FallingBallEnv.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 16 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Cosine-Gated LSTM (CGLSTM) for Prediction: Methods</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Architecture: Integrated cosine similarity-based gating into LSTM, enhancing long-term dependency modeling (Chapter 6, p. 96).</li>
							<li class="fragment">Training: Utilized backpropagation through time (BPTT) in SocNavGym and FallingBallEnv, optimizing for sequence prediction (Chapter 6, p. 98).</li>
							<li class="fragment">Integration: Combined with DreamerV3 and SAC for RL enhancement (Chapter 6, p. 114; Chapter 7, p. 124).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the CGLSTM architecture, training process, and integration with RL, referencing the diagram showing its structure or integration in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 17 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Cosine-Gated LSTM (CGLSTM) for Prediction: Evaluation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, FallingBallEnv, and additional tasks (e.g., Adding Problem, Row-wise MNIST) (Chapter 6, p. 103–114).</li>
							<li class="fragment">Metrics: Evaluated with Mean Absolute Error (MAE), Mean Squared Error (MSE), and accuracy (Chapter 6, p. 103).</li>
							<li class="fragment">Comparison: Compared against LSTM, GRU, and RAU for sequence prediction performance (Chapter 6, p. 103).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of CGLSTM across environments, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 18 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Cosine-Gated LSTM (CGLSTM) for Prediction: Results</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">FallingBallEnv: 30% MAE reduction compared to LSTM, GRU, and RAU (Chapter 6, p. 103).</li>
							<li class="fragment">SocNavGym: Improved sequence prediction, enhancing RL decision-making by 5% in cumulative rewards (Chapter 6, p. 113–114).</li>
							<li class="fragment">Additional Tasks: Outperformed baselines in Adding Problem, MNIST, FashionMNIST, IMDB, and Penn Treebank (Chapter 6, p. 108–111).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight CGLSTM results, emphasizing MAE reduction and reward improvements, referencing the diagram showing performance graphs or comparisons in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 19 - ADAPTIVE PREDICTION HORIZONS IN RL: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL: Challenges/Limitations</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Fixed Horizons: Current RL and predictive models (e.g., 2StepAhead) lack adaptability, reducing performance in dynamic environments (Chapter 7, p. 122).</li>
							<li class="fragment">Computational Cost: Entropy-based adaptation increases processing demands, potentially impacting real-time performance (Chapter 7, p. 125).</li>
							<li class="fragment">Exploration Uncertainty: Challenges in balancing exploration and exploitation in continuous action spaces (Chapter 7, p. 121).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of adaptive prediction horizons in RL, emphasizing fixed horizons, computational cost, and exploration uncertainty, referencing the diagram illustrating these in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 20 - ADAPTIVE PREDICTION HORIZONS IN RL: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL: Methods</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Entropy-Driven Adaptation: Dynamically adjusts prediction horizons based on policy entropy, enhancing RL adaptability (Chapter 7, p. 125).</li>
							<li class="fragment">Integration: Combined with CGLSTM and SAC, optimizing for continuous action spaces (Chapter 7, p. 124).</li>
							<li class="fragment">Framework: Proposed adaptive horizon selection using entropy measures, integrated into DreamerV3 for comparison (Chapter 7, p. 127–128).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the entropy-driven adaptive horizon methods in RL, integration with RL, and framework, referencing the diagram showing the mechanism or integration in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 21 - ADAPTIVE PREDICTION HORIZONS IN RL: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL: Evaluation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, FallingBallEnv, and LunarLander-v2, focusing on dynamic scenarios (Chapter 7, p. 132).</li>
							<li class="fragment">Metrics: Evaluated success rates, cumulative rewards, and inference time (Chapter 7, p. 136).</li>
							<li class="fragment">Comparison: Compared against fixed-horizon models (e.g., 2StepAhead) and baseline RL (SAC, DreamerV3) (Chapter 7, p. 138).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of adaptive prediction horizons in RL across environments, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 22 - ADAPTIVE PREDICTION HORIZONS IN RL: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL: Results</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">SocNavGym: 15% improvement in success rates in high-entropy scenarios, addressing adaptability limitations (Chapter 7, p. 138).</li>
							<li class="fragment">FallingBallEnv: Enhanced prediction accuracy, reducing MAE by 10% with adaptive horizons (Chapter 7, p. 141).</li>
							<li class="fragment">LunarLander-v2: Improved cumulative rewards by 8%, maintaining 2% increase in inference time (Chapter 7, p. 141).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight adaptive prediction horizon results in RL, emphasizing success rate improvements and efficiency, referencing the diagram showing performance graphs or comparisons in SocNavGym.
					</aside>
				</section>

				<!-- =========== CONCLUSION AND FUTURE WORK: SLIDE 23 - CONCLUSION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Conclusion</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Contributions: Developed CGLSTM, adaptive prediction horizons, and integrated RL (SAC, DreamerV3, DQN, DDPG, PPO, A2C) to address sample efficiency, fixed horizons, and exploration challenges (Chapter 8, p. 147–149).</li>
							<li class="fragment">Impact: Improved success rates, efficiency, and social compliance in SocNavGym, FallingBallEnv, and LunarLander-v2, overcoming current limitations (Chapter 8, p. 150–151).</li>
							<li class="fragment">Future Work: Extend to real-world deployment, address sensor noise, and explore broader applications like multi-robot systems (Chapter 8, p. 151–153).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/conclusion_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Summarize your thesis contributions, impact, and future directions, referencing the diagram illustrating contributions or future research paths, preparing for Q&A.
					</aside>
				</section>

				<!-- =========== PERSONAL: SLIDE 24 - ABOUT ME =========== -->
				<section data-background="img/aston_background.jpg" data-transition="slide">
					<h3>About Me</h3>
					<div style="text-align: left; font-size: 0.85em;">
						<ul>
							<li class="fragment">Goodluck Oguzie</li>
							<li class="fragment">PhD in Robotics, <a href="https://robolab.unex.es/">Universidad de Extremadura</a>, Cáceres, Spain
								<div class="fragment" style="text-align: center;">
									<img src="img/caceres.jpg" width="70%" style="border: 2px solid white;"/>
								</div>
							</li>
							<li class="fragment">PhD Focus: Robotics, Active Perception, POMDP & Particle Filters</li>
							<li class="fragment">Career: Joined Aston University in August 2018 as Lecturer, now Senior Lecturer</li>
							<li class="fragment">Lab: <a href="https://arp-lab.com">Autonomous Robotics and Perception Lab</a></li>
						</ul>
					</div>
					<aside class="notes">
						Highlight your journey from PhD to current role, and briefly mention how it ties to social navigation research.
					</aside>
				</section>

			</div>
		</div>

		<script>
			Reveal.initialize({
				hash: true,
				width: 1600,
				height: 900,
				slideNumber: true,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>

		<!-- <div class="footer">
			<span style="font-size: 0.7em;">https://ljmanso.github.io/r</span>
		</div> -->
	</body>
</html>
