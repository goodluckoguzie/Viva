

<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>PhD Viva Presentation - Goodluck Oguzie</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <!-- Reveal.js Core CSS and JS -->
  <link rel="stylesheet" href="dist/reset.css" />
  <link rel="stylesheet" href="dist/reveal.css" />
  <link rel="stylesheet" href="dist/theme/white.css" />
  <link rel="stylesheet" href="plugin/highlight/monokai.css" />

  <script src="dist/reveal.js"></script>
  <script src="plugin/notes/notes.js"></script>
  <script src="plugin/markdown/markdown.js"></script>
  <script src="plugin/highlight/highlight.js"></script>
  <script src="plugin/math/math.js"></script>

  <!-- Custom CSS -->
  <link rel="stylesheet" href="mycss.css" />

  <script type="text/javascript">
    window.addEventListener("load", function() {
      var revealDiv = document.querySelector("body div.reveal");
      var footer = document.querySelector(".footer");
      if (footer) revealDiv.appendChild(footer);
    });
  </script>

  <style>
    /* Slide number styling */
    .reveal .slide-number {
      font-size: 20pt;
      color: #fff;
    }
    video::-webkit-media-controls-panel {
      background-image: linear-gradient(transparent, transparent) !important;
    }
    .reveal section div ul li span {
      line-height: 1.2;
    }
    .fragment.fade-in {
      opacity: 0;
      visibility: hidden;
      transition: opacity 0.5s ease-in-out;
    }
    .fragment.fade-in.visible {
      opacity: 1;
      visibility: visible;
    }
    .fragment.slide-in {
      transform: translateY(100%);
      transition: transform 0.5s ease-in-out;
    }
    .fragment.slide-in.visible {
      transform: translateY(0);
    }
    /* Text block styling ‚Äì no background */
    .textBlock {
      margin: 0 auto;
      line-height: 1.5;
      padding: 15px;
      border-radius: 5px;
      display: inline-block;
      max-width: 80%;
      text-align: center;
    }
    /* Section title styling */
    .section-title {
      color: white;
      text-align: center;
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
    }
    /* Final link styling */
    .final-link {
      font-size: 1.2em;
      color: #00A9D4;
      text-decoration: none;
      margin-top: 20px;
      display: block;
    }
  </style>
</head>
<body>
  <div class="reveal">
    <div class="slides">
      
      <!-- ========================================= -->
      <!-- 1. TITLE & OVERVIEW                      -->
      <!-- ========================================= -->

      <!-- Slide 1: Title Slide -->
      <section data-background="img/aston_title_background.jpg" data-background-size="cover" data-background-position="0 20px">
        <h2 style="color: white; text-align: left; margin-left: 40px;">
          Enhancing Robot Social Navigation<br>
          with Reinforcement Learning<br>
          and Advanced Predictive Models
        </h2>
        <h3 style="color: white; text-align: left; margin-left: 40px;">
          <span style="font-size: 0.9em;">Goodluck Oguzie</span><br>
          <span style="font-size: 0.8em;">190212683@aston.ac.uk</span>
        </h3>
      </section>


<!-- Slide 2: Presentation Outline -->
<section
  data-background="img/aston_slides_background_22.png"
  data-background-size="cover"
  data-background-position="top"
  data-transition="slide"
>
  <div style="margin-top: 100px; text-align: center;">
    <h2 style="color: white; margin-bottom: 20px;">üîé Presentation Outline</h2>
  </div>

  <div
    style="
      display: flex;
      justify-content: center;
      align-items: flex-start;
      padding-top: 40px;
      font-size: 1em;
      color: white;
    "
  >
    <!-- Left Column: Context & Background -->
    <div style="flex: 0 0 40%; text-align: left; padding-right: 30px;">
      <ol style="list-style-position: inside;">
        <li>Context, Motivation &amp; Problem</li>
        <li>Reinforcement Learning Basics</li>
        <li>Predictive Models Overview</li>
        <li>Environments </li>
      </ol>
    </div>

    <!-- Right Column: Key Contributions & Conclusion -->
    <div style="flex: 0 0 40%; text-align: left; padding-left: 30px;">
      <ol start="5" style="list-style-position: inside;">
        <li><strong>Key Contributions:</strong></li>
        <ul style="list-style-position: inside; margin-left:20px;">
          <li>Predictive World Models</li>
          <li>Cosine-Gated LSTM (CGLSTM)</li>
          <li>Adaptive Prediction Horizons</li>
        </ul>
        <li>Conclusion &amp; Future Work</li>
      </ol>
    </div>
  </div>
</section>



      <!-- ========================================= -->
<!-- 2. CONTEXT & SCOPE & APPROACHES            -->
<!-- ========================================= -->

<!-- Slide 1: What is Social Robot Navigation? -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover">
  <h2 style="color: white; text-align: center;">ü§ñ What is Social Robot Navigation?</h2>
  <div style="text-align: center; padding-top: 30px;">
    <video muted autoplay loop src="img/socialrobot.mp4" width="60%"></video>
  </div>
  <div style="color: white; text-align: center; padding-top: 20px;">
    <p style="font-size: 1.1em;">
      üí° <strong>Definition:</strong><br>
      Robots navigating among humans while respecting social norms, ensuring safety, and operating efficiently.
    </p>
    <p style="font-size: 1.1em;">
      ‚úîÔ∏è <strong>Importance:</strong><br>
      Social robot navigation is crucial for seamless integration into environments such as healthcare, hospitality, and public spaces. Advanced predictive decision-making is essential to manage inherent unpredictability.
    </p>
  </div>
</section>
<!-- Slide 3: Approaches to Social Robot Navigation -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover">
  <div style="color: white; text-align: center; padding-top: 20px;">
    <table style="width: 80%; margin: auto; border-collapse: collapse;">
      <thead style="background-color: #003087;">
        <tr>
          <th style="padding: 10px; border: 1px solid white;">Approach</th>
          <th style="padding: 10px; border: 1px solid white;">‚úÖ Strength</th>
          <th style="padding: 10px; border: 1px solid white;">‚ö†Ô∏è Weakness</th>
        </tr>
      </thead>
      <tbody>
        <tr class="fragment">
          <td style="padding: 10px; border: 1px solid white;">Rule Base (Arkin, 1998)</td>
          <td style="padding: 10px; border: 1px solid white;">Simple &amp; efficient</td>
          <td style="padding: 10px; border: 1px solid white;">Fails in dynamic settings</td>
        </tr>
        <tr class="fragment">
          <td style="padding: 10px; border: 1px solid white;">Social Force Models (Helbing &amp; Molnar, 1995)</td>
          <td style="padding: 10px; border: 1px solid white;">Good for crowd modeling</td>
          <td style="padding: 10px; border: 1px solid white;">Limited adaptability</td>
        </tr>
        <tr class="fragment">
          <td style="padding: 10px; border: 1px solid white;">RVO2 (Van den Berg et al., 2011)</td>
          <td style="padding: 10px; border: 1px solid white;">Real-time collision avoidance; effective in dynamic scenarios</td>
          <td style="padding: 10px; border: 1px solid white;">Limited in long-term planning and human comfort prediction</td>
        </tr>
        <tr class="fragment">
          <td style="padding: 10px; border: 1px solid white;">Reinforcement Learning (Mnih et al., 2015)</td>
          <td style="padding: 10px; border: 1px solid white;">Learns dynamically</td>
          <td style="padding: 10px; border: 1px solid white;">Requires extensive training</td>
        </tr>
      </tbody>
    </table>
    <p style="margin-top: 15px; font-size: 1.1em;">
      <span class="fragment">üí° <strong>Our Research:</strong> Integrates reinforcement learning with advanced predictive models to overcome these limitations.</span>
    </p>
  </div>
</section>


<!-- Slide 4: Context & Scope -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover">
  <!-- Problem Statement at the Top -->
  <div style="color: white; text-align: center; font-size: 1.1em; padding-top: 20px;">
    <p>
      üöÄ <strong>The Problem:</strong><br>
      "Robots struggle to navigate in social environments due to unpredictable human behavior."
    </p>
  </div>
  
  <!-- Embedded Video at the Center -->
  <div style="text-align: center; padding-top: 20px;">
    <video muted autoplay loop src="img/problem.mp4" width="60%"></video>
  </div>
  
  <!-- Predict vs. React Text at the Bottom -->
  <div style="color: white; text-align: center; font-size: 1.1em; padding-top: 20px;">
    <p style="font-style: italic;">
      <strong>Predict vs. React:</strong> 
    </p>
  </div>
</section>




<!-- Slide 7: Research Questions -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover">
  <h2 style="color: white; text-align: center;">üîç Research Questions</h2>
  <div style="color: white; text-align: center; font-size: 1em; padding-top: 30px;">
    <p class="fragment">
      ‚ùì <strong>Q1:</strong> How do predictive world models improve decision-making in Social Robot Navigation (SocNav)?
    </p>
    <p class="fragment">
      ‚ùì <strong>Q2:</strong> What challenges arise when transitioning Reinforcement Learning applications from discrete to continuous action spaces in Social Robot Navigation, and how can we address the challenges?
    </p>
  </div>
</section>


<!-- ========================================= -->
<!-- 4. REINFORCEMENT LEARNING                 -->
<!-- ========================================= -->

<!-- Slide 10: RL Fundamentals (Short Version) -->
<section 
  data-background="img/aston_slides_background_22.png"
  data-background-size="cover"
  data-background-position="0 -20px"
>
  <!-- Short Heading -->
  <div style="text-align: center; padding-top: 20px;">
    <p style="color: white; font-size: 1.3em; font-weight: bold;">RL Fundamentals</p>
  </div>
  
  <!-- RL Basics Diagram -->
  <div style="text-align: center; padding-top: 20px; min-height: 300px;">
    <img 
      src="img/rl_basics_diagram.jpg" 
      width="70%" 
      style="display: block; margin: 0 auto; border: 2px solid white;" 
      alt="RL Basics Diagram" 
    />
  </div>
  
  <!-- Revised Caption with Magnifying Glass Icon -->
  <div style="text-align: center; padding-top: 15px;">
    <p style="color: white; font-size: 1.1em;">
      üîç Reinforcement Learning (RL) is a method by which an agent learns to make optimal decisions by taking actions in an environment to maximize cumulative reward (Sutton &amp; Barto, 2018).
    </p>
  </div>
</section>



<!-- Slide 11: RL Algorithms: Critical Comparison (No Heading) -->
<section data-background="img/aston_slides_background_22.png">
  <div style="text-align: center; color: white; padding-top: 40px;">
    <table style="margin: 0 auto; width: 85%; border-collapse: collapse; font-size: 0.9em;">
      <thead style="background-color: #003087; color: white;">
        <tr>
          <th style="padding: 8px; border: 1px solid white;">RL Algorithm</th>
          <th style="padding: 8px; border: 1px solid white;">üéØ Strengths</th>
          <th style="padding: 8px; border: 1px solid white;">‚ö†Ô∏è Limitations </th>
        </tr>
      </thead>
      <tbody>
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white;">DQN (Mnih et al., 2015)</td>
          <td style="padding: 8px; border: 1px solid white;">Efficient in discrete tasks</td>
          <td style="padding: 8px; border: 1px solid white;">Not suited for continuous or complex action spaces</td>
        </tr>
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white;">DDPG (Lillicrap et al., 2015)</td>
          <td style="padding: 8px; border: 1px solid white;">Effective in continuous control tasks</td>
          <td style="padding: 8px; border: 1px solid white;">Sensitive to hyperparameters and exploration noise</td>
        </tr>
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white;">PPO (Schulman et al., 2017)</td>
          <td style="padding: 8px; border: 1px solid white;">Stable learning; good sample efficiency</td>
          <td style="padding: 8px; border: 1px solid white;">Sensitive to hyperparameter tuning</td>
        </tr>
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white;">TD3 (Fujimoto et al., 2018)</td>
          <td style="padding: 8px; border: 1px solid white;">Addresses overestimation bias in DDPG</td>
          <td style="padding: 8px; border: 1px solid white;">Still requires careful hyperparameter tuning</td>
        </tr>
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white;">SAC (Haarnoja et al., 2018)</td>
          <td style="padding: 8px; border: 1px solid white;">Robust for continuous control; promotes exploration</td>
          <td style="padding: 8px; border: 1px solid white;">Higher computational demands</td>
        </tr>
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white;">DreamerV3 (Hafner et al., 2023)</td>
          <td style="padding: 8px; border: 1px solid white;">Learns a latent world model for planning</td>
          <td style="padding: 8px; border: 1px solid white;">Sensitive to model inaccuracies and observation noise</td>
        </tr>
      </tbody>
    </table>
  </div>
</section>


      
<!-- ========================================= -->
<!-- 5. PREDICTIVE MODELS                     -->
<!-- ========================================= -->


<!-- Slide 1: Blank-Style Title Slide -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover">
  <div style="margin-top: 200px; text-align: center;">
    <h2 class="section-title" style="color: white;">
      Predictive Models
    </h2>
  </div>
</section>


<!-- Slide 2: Definition of Predictive Models -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover">
  <div style="text-align: center; padding-top: 100px;">
    <p style="color: white; font-size: 1.3em; max-width: 80%; margin: 0 auto;">
      ü§ù Predictive Models are machine learning models that learn from sequential data to forecast future states.
    </p>
  </div>
</section>


<!-- Slide 3: Comparison of Predictive Models (No Heading) -->
<section data-background="img/aston_slides_background_22.png">
  <div style="text-align: center; color: white; padding-top: 20px;">
    <table style="margin: 0 auto; width: 90%; border-collapse: collapse; font-size: 0.9em;">
      <thead style="background-color: #003087; color: white;">
        <tr>
          <th style="padding: 8px; border: 1px solid white;">Model</th>
          <th style="padding: 8px; border: 1px solid white;">Description</th>
          <th style="padding: 8px; border: 1px solid white;">üéØ Pros</th>
          <th style="padding: 8px; border: 1px solid white;">‚ö†Ô∏è Cons</th>
        </tr>
      </thead>
      <tbody>
        <!-- RNN -->
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white; color: white;">
            <strong>RNN</strong><br>
            (<em>Rumelhart et al., 1986</em>)
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            Basic recurrent net passing hidden states across time
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            üéØ Simple, good for short sequences
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            ‚ö†Ô∏è Vanishing/exploding gradients for long sequences
          </td>
        </tr>
        <!-- LSTM -->
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white; color: white;">
            <strong>LSTM</strong><br>
            (<em>Hochreiter &amp; Schmidhuber, 1997</em>)
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            Adds gating (input, forget, output) for long-term dependencies
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            üéØ Mitigates vanishing gradients; better for lengthy sequences
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            ‚ö†Ô∏è More parameters, heavier computation
          </td>
        </tr>
        <!-- GRU -->
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white; color: white;">
            <strong>GRU</strong><br>
            (<em>Cho et al., 2014</em>)
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            A simplified LSTM with fewer gates
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            üéØ Fewer parameters, faster training than LSTM
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            ‚ö†Ô∏è May capture slightly less nuance for very long sequences
          </td>
        </tr>
        <!-- Transformers -->
        <tr class="fragment">
          <td style="padding: 8px; border: 1px solid white; color: white;">
            <strong>Transformers</strong><br>
            (<em>Vaswani et al., 2017</em>)
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            Employ self-attention for global context
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            üéØ Excels at capturing long-range dependencies
          </td>
          <td style="padding: 8px; border: 1px solid white; color: white;">
            ‚ö†Ô∏è High memory &amp; compute requirements
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</section>





<!-- Slide X: World Models (Ha & Schmidhuber, 2018) -->
<section
  data-background="img/aston_slides_background_22.png"
  data-background-size="cover"
>
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">
    World Models (Ha &amp; Schmidhuber, 2018)
  </h2>

  <!-- Centered JPG Image -->
  <div style="text-align: center; margin-bottom: 20px;">
    <!-- Replace 'img/world_model_schematic.jpg' with your actual .jpg file path/name -->
    <img
      src="img/world_model_schematic.jpg"
      alt="World Models Diagram"
      width="60%"
      style="border: 2px solid white; border-radius: 5px;"
    />
  </div>
  <!-- No bullet points, just the heading and image -->
</section>


<!-- Slide X+1: Dreamer Limitations -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">
    Dreamer: A Step Forward, but Still Not Adaptive Enough
  </h2>
  <div style="text-align: center; padding-top: 20px; min-height: 200px;">
    <ul style="color: white; text-align: left; display: inline-block; max-width: 75%; font-size: 1.1em;">
      <li style="margin-bottom: 10px;">‚úÖ <strong>Builds on World Models</strong></li>
      <li style="margin-bottom: 10px;">‚ö†Ô∏è <strong>Does not consider all the possible actions</strong></li>
      <li style="margin-bottom: 10px;">‚ö†Ô∏è <strong>Fixed Prediction Horizon (one step ahead)</strong></li>
      <li style="margin-bottom: 10px;">‚è± <strong>Limited Real-Time Prediction Horizon Adaptation</strong></li>
    </ul>
  </div>
</section>



      
      <!-- ========================================= -->
<!-- 6. ENVIRONMENTS USED                     -->
<!-- ========================================= -->

<!-- Slide 19: Section Title: Environments Used -->
<section 
  data-background="img/aston_slides_background_22.png" 
  data-background-size="cover"
>
  <h2 class="section-title" style="color: white;">Environments Used</h2>
</section>

<!-- Slide 20: FallingBallEnv -->
<section 
  data-background="img/aston_slides_background_22.png" 
  data-background-position="0 -20px"
>
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">‚öóÔ∏è FallingBallEnv</h2>
  <div style="text-align: center; position: relative; min-height: 300px; padding-top: 50px;">
    <div style="padding-bottom: 20px;">
      <!-- Updated video source -->
      <video muted data-autoplay src="img/FallingBallEnv.webm" width="30%"></video>
    </div>
    <!-- Single Bullet -->
    <p style="font-size: 1em; color: white; padding-top: 20px;">
      üìå Purpose: Toy environment for sequence prediction.
    </p>
  </div>
</section>


<!-- Slide 21: LunarLander‚Äëv2 -->
<section 
  data-background="img/aston_slides_background_22.png" 
  data-background-position="0 -20px"
>
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">ü™Ç LunarLander‚Äëv2</h2>
  <div style="text-align: center; position: relative; min-height: 300px; padding-top: 50px;">
    <div style="padding-bottom: 20px;">
      <!-- Updated video for LunarLander‚Äëv2 -->
      <video muted data-autoplay src="img/LunarLander.webm" width="40%" style="display: block; margin: 0 auto;"></video>
    </div>
    <!-- Single Bullet -->
    <p style="font-size: 1em; color: white; padding-top: 20px;">
      üìå Purpose: A Simple Continuous control task for RL.
    </p>
  </div>
</section>


<!-- Slide 22: SocNavGym -->
<section 
  data-background="img/aston_slides_background_22.png" 
  data-background-position="0 -20px"
>
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üèô SocNavGym</h2>
  <div style="text-align: center; position: relative; min-height: 300px; padding-top: 50px;">
    <div style="padding-bottom: 20px;">
      <!-- Replace with your SocNavGym video or screenshot -->
      <video muted data-autoplay src="img/whypredictivemodellimitation.mp4" width="30%"></video>
    </div>
    <!-- Single Bullet -->
    <p style="font-size: 1em; color: white; padding-top: 20px;">
      üìå Purpose: Benchmark for social navigation tasks.
    </p>
  </div>
</section>

<!-- Slide 23: LiteSocNavGym -->
<section 
  data-background="img/aston_slides_background_22.png" 
  data-background-position="0 -20px"
>
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üè∑ LiteSocNavGym</h2>
  <div style="text-align: center; position: relative; min-height: 300px; padding-top: 50px;">
    <div style="padding-bottom: 20px;">
      <!-- Updated video source for LiteSocNavGym -->
      <video muted data-autoplay src="img/LITESOCNAVGYM.webm" width="30%"></video>
    </div>
    <!-- Single Bullet -->
    <p style="font-size: 1em; color: white; padding-top: 20px;">
      üìå Purpose: Lightweight variant for quicker iteration.
    </p>
  </div>
</section>

<!-- ========================================= -->
<!-- Slide 7: Predictive World Models         -->
<!-- with Vertical (Up/Down) Navigation        -->
<!-- ========================================= -->

<!-- Outer section for vertical slides -->
<section>

  <!-- Sub-Slide 10.1: Main Content -->
  <section id="predictiveSlide"
           data-background="img/aston_slides_background_22.png"
           data-background-size="cover">
    <h2 style="color: white; text-align: center; margin-bottom: 20px;">
      Predictive World Models for Social Navigation (Contribution 1)
    </h2>
    <div style="text-align: center; padding-top: 20px; min-height: 150px;">
      <ul style="color: white; text-align: left; display: inline-block; max-width: 75%; font-size: 1.2em;">
        <li style="margin-bottom: 10px;">The goal is to mitigate limitations of World Models:</li>
        <li style="margin-bottom: 10px;">üîé single-step prediction</li>
        <li style="margin-bottom: 10px;">üìå limited actions</li>
        <li style="margin-bottom: 10px;">üéØ enabling multi-step, adaptive decision-making in dynamic social environments.</li>
      </ul>
    </div>
  </section>

  <!-- Sub-Slide 10.2: PDF Embedding -->
  <section data-background="img/aston_slides_background_22.png"
           data-background-size="cover">
    <div style="text-align: center; margin-top:70px;">
      <h3 style="color:white;">Paper PDF / Extended Explanation</h3>
      <iframe src="articles/UKCI_2023__Predictive_World_Models_for_Social_Navigation.pdf"
              width="90%"
              height="600px"
              style="border:none;">
      </iframe>
    </div>
  </section>

</section>


<!-- Slide: üß© 2StepAhead Predictive World Model -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üß© 2StepAhead Predictive World Model</h2>
  <div style="text-align: center; padding-top: 50px; min-height: 300px;">
    <div style="padding-bottom: 20px;">
      <!-- Retain the image for 2StepAhead -->
      <img src="img/figure1.2_2StepAhead.jpg" width="70%" style="display: block; margin: 0 auto;">
    </div>
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      üîç Predicts hidden &amp; latent states two steps ahead.
    </div>
  </div>
</section>

<!-- Slide: üéõ Multi Action State Predictive Model (MASPM) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üéõ Multi Action State Predictive Model (MASPM)</h2>
  <div style="text-align: center; padding-top: 50px; min-height: 300px;">
    <div style="padding-bottom: 20px;">
      <!-- Retain the image for MASPM -->
      <img src="img/figure1.3_MASPM.jpg" width="70%" style="display: block; margin: 0 auto;">
    </div>
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      üìå Predicts outcomes for all available actions.
    </div>
  </div>
</section>

<!-- Slide: üîó 2StepAhead-MASPM (Hybrid Model) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üîó 2StepAhead-MASPM (Hybrid Model)</h2>
  <div style="text-align: center; padding-top: 50px; min-height: 300px;">
    <div style="padding-bottom: 20px;">
      <!-- Retain the image for Hybrid Model -->
      <img src="img/figure1.4_Hybrid.jpg" width="70%" style="display: block; margin: 0 auto;">
    </div>
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      üîó Combines 2StepAhead‚Äôs efficiency with MASPM‚Äôs comprehensive evaluation.
    </div>
  </div>
</section>
      
<!-- Remove slide: "üß™ Experimental Setup & Metrics" -->

<!-- Slide: ‚è± Training Metrics -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">‚è± Training Metrics</h2>
  <div style="text-align: center; padding-top: 50px; min-height: 300px;">
    <div style="padding-bottom: 20px;">
      <img src="img/TrainingMetrics.jpg" width="60%" style="display: block; margin: 0 auto;" />
    </div>
    <div style="font-size: 1em; color: white; text-align: center; margin-top: 20px;">
      ‚è± Full convergence reached in ~200k episodes with top rewards ~0.75.
    </div>
  </div>
</section>

<!-- Slide: üéØ Testing Metrics (1) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üéØ Testing Metrics (1)</h2>
  <div style="text-align: center; padding-top: 50px; min-height: 300px;">
    <div style="padding-bottom: 20px;">
      <img src="img/TestingMetrics1.jpg" width="60%" style="display: block; margin: 0 auto;" />
    </div>
    <div style="font-size: 1em; color: white; text-align: center; margin-top: 20px;">
      ‚úÖ Testing results indicate higher rewards and success rates for our methods.
    </div>
  </div>
</section>

<!-- Slide: üéØ Testing Metrics (2) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üéØ Testing Metrics (2)</h2>
  <div style="text-align: center; padding-top: 50px; min-height: 300px;">
    <div style="padding-bottom: 20px;">
      <img src="img/TestingMetrics2.jpg" width="80%" style="display: block; margin: 0 auto;" />
    </div>
    <div style="font-size: 1em; color: white; text-align: center; margin-top: 20px;">
      üéØ 2StepAhead-MASPM demonstrates superior multi-metric performance.
    </div>
  </div>
</section>

<!-- ========================================= -->
<!-- Slide: Cosine-Gated LSTM (CGLSTM) with PDF -->
<!-- ========================================= -->
<section>
  <!-- Sub-Slide 1: Title & Explanation -->
  <section id="cglstmSlide"
           data-background="img/aston_slides_background_22.png"
           data-background-size="cover"
           style="padding: 60px 0;"
  >
    <h2 
      style="
        color: white; 
        text-align: center; 
        margin-bottom: 30px; 
        font-size: 2em;
      "
    >
      Cosine-Gated LSTM (CGLSTM)
    </h2>

    <div style="text-align: center; margin-top: 20px;">
      <!-- Contribution 2 Label -->
      <p style="color: white; font-size: 1.2em; margin-bottom: 20px;">
        <strong>Contribution 2:</strong>
      </p>

      <!-- Bullet List -->
      <ul 
        style="
          color: white; 
          text-align: left; 
          display: inline-block; 
          max-width: 75%; 
          font-size: 1.2em; 
          line-height: 1.4;
        "
      >
        <li style="margin-bottom: 10px;">
          ü§ñ Aims to improve sequence prediction by focusing on directional alignment.
        </li>
        <li style="margin-bottom: 10px;">
          üìå Builds on limitations observed in previous LSTM experiments (e.g., in SocNavGym).
        </li>
      </ul>
    </div>
  </section>

  <!-- Sub-Slide 2: PDF Embedding -->
  <section 
    data-background="img/aston_slides_background_22.png"
    data-background-size="cover"
  >
    <div style="text-align: center; margin-top: 70px;">
      <h3 style="color: white;">Paper PDF / Extended Explanation</h3>
      <iframe 
        src="articles/Cosine_Gated_LSTM_main.pdf"
        width="90%"
        height="600px"
        style="border:none;"
      >
      </iframe>
    </div>
  </section>
</section>


<!-- Slide: üîç Fundamentals & Limitations (with image) -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üîç Fundamentals &amp; Limitations</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <!-- Image restored here -->
    <img src="img/limitationforCGLSTM.jpg" width="50%" style="display: block; margin: 0 auto;" />
    <p style="color: white; text-align: center; font-size: 1.2em; margin-top: 20px;">
      üìå They struggle with dynamic environments when predicting further ahead.
    </p>
  </div>
</section>

<!-- Slide: üí° Why Cosine-Gated LSTM? -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üí° Why Cosine-Gated LSTM?</h2>
  <div style="text-align: center; padding-top: 50px;">
    <ul class="textBlock" style="color: white; font-size: 1.2em; text-align: left; display: inline-block; max-width: 75%;">
      <li class="fragment fade-in">
        ü§ñ Emphasizes directional alignment in sequence prediction.
      </li>
      <li class="fragment fade-in">
        üìå Addresses the limitations of vanilla LSTM in handling noisy, dynamic data.
      </li>
    </ul>
  </div>
</section>

<!-- Slide: üèóÔ∏è CGLSTM Architecture -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üèóÔ∏è CGLSTM Architecture</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/CGLSTMArchitecture.jpg" width="50%" style="display: block; margin: 0 auto;" />
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      ‚öôÔ∏è Dynamically weighs new inputs vs. hidden states based on similarities.
    </div>
  </div>
</section>

<!-- Slide: ‚è± FallingBallEnv Results -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">‚è± FallingBallEnv Results</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/fallingballenv_cglstm_results.jpg" width="60%" style="display: block; margin: 0 auto;" />
    <div style="font-size: 1em; color: white; text-align: center; margin-top: 20px;">
      üìå CGLSTM outperforms LSTM, GRU, and Transformer in the falling ball predictions.
    </div>
  </div>
</section>

<!-- Slide: üéØ Benchmark Tasks (MNIST, etc.) -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üéØ Benchmark Tasks (MNIST, etc.)</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/cgltsmtestResult.jpg" width="70%" style="display: block; margin: 0 auto;" />
    <div style="font-size: 1em; color: white; text-align: center; margin-top: 20px;">
      ‚úÖ Highest accuracy overall.
    </div>
  </div>
</section>

<!-- Slide: ‚è≤Ô∏è Training & Testing Times (Moved after Benchmark Tasks) -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">‚è≤Ô∏è Training &amp; Testing Times</h2>
  <div style="text-align: center; padding-top: 50px; min-height: 300px;">
    <div style="padding-bottom: 20px;">
      <img src="img/cgltsmtestTimeResult.jpg" width="70%" style="display: block; margin: 0 auto;" />
    </div>
    <div style="font-size: 1em; color: white; text-align: center; margin-top: 20px;">
      üìä GRU is faster, but CGLSTM uses ~5% more time for superior accuracy.
    </div>
  </div>
</section>

<!-- Slide: ü§ñ SocNavGym: Realistic Scenario -->
<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">ü§ñ SocNavGym: Realistic Scenario</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/cgltsmtestResultforsocnav.jpg" width="70%" style="display: block; margin: 0 auto;" />
    <div style="font-size: 1em; color: white; text-align: center; margin-top: 20px;">
      üìå Achieves the lowest MAE across prediction horizons (k=1 to k=10).
    </div>
  </div>
</section>


<!-- ========================================= -->
<!-- Adaptive Horizons Chapter Slide Deck      -->
<!-- ========================================= -->


<!-- Slide A1: Chapter Title with Contributions (Contribution 3) -->
<section 
  data-background="img/aston_slides_background_22.png" 
  data-background-size="cover"
  style="padding: 60px 0;"
>
  <h2 
    style="
      color: white; 
      text-align: center; 
      margin-bottom: 30px; 
      font-size: 2em;
    "
  >
    Entropy‚ÄêDriven Adaptive Prediction Horizons
  </h2>

  <div style="text-align: center; margin-top: 20px;">
    <p style="color: white; font-size: 1.2em; margin-bottom: 20px;">
      <strong>Contribution 3:</strong>
    </p>
    <ul 
      style="
        color: white; 
        text-align: left; 
        display: inline-block; 
        max-width: 75%; 
        font-size: 1.2em; 
        line-height: 1.4;
      "
    >
      <li style="margin-bottom: 10px;">‚úÖ Propose an entropy-driven adaptive horizon within SAC.</li>
      <li style="margin-bottom: 10px;">ü§ñ Integrate CGLSTM into DreamerV3 for enhanced predictive modeling.</li>
      <li style="margin-bottom: 10px;">üìä Benchmark vs. SAC, PPO, TD3, DDPG, DreamerV3 variants.</li>
    </ul>
  </div>
</section>



<!-- ========================================= -->
<!-- Proposed Methods Section -->
<!-- ========================================= -->

<!-- Slide A6: Proposed Methods (Overview) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üîë Proposed Methods</h2>
  <div style="text-align: center; padding-top: 50px;">
    <ul class="textBlock" style="color: white; font-size: 1.2em; list-style: none; padding: 0;">
      <li style="margin-bottom: 10px;">üöÄ DreamerV3 + CGLSTM</li>
      <li style="margin-bottom: 10px;">üîó 2StepAhead-MASPM (Fixed Horizon)</li>
      <li style="margin-bottom: 10px;">ü§ñ SAC + CGLSTM (Adaptive Horizon)</li>
    </ul>
  </div>
</section>


<!-- Slide A7: Proposed: DreamerV3 + CGLSTM -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üöÄ Proposed: DreamerV3 + CGLSTM</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/DreamerV3_CGLSTM.JPG" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 30px; color: white; text-align: center; font-size: 1.2em;">
      ü§ñ Enhances State Prediction.
    </div>
  </div>
</section>

<!-- Slide A8: Proposed: 2StepAhead-MASPM (Fixed Horizon) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üîó Proposed: 2StepAhead-MASPM (Fixed Horizon)</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/figure1.4_Hybrid.jpg" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 30px; color: white; text-align: center; font-size: 1.2em;">
      ‚öôÔ∏è Provides a strong baseline for adaptive horizon comparison.
    </div>
  </div>
</section>

<!-- Slide A9: Proposed: SAC + CGLSTM (Adaptive Horizon) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">ü§ñ Proposed: SAC + CGLSTM (Adaptive Horizon)</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/SAC_CGLSTM_Adaptive.jpg" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 30px; color: white; text-align: center; font-size: 1.2em;">
      Dynamically adjusts prediction horizon via action entropy.
    </div>
  </div>
</section>

<!-- ========================================= -->
<!-- Preliminary Experiments Section -->
<!-- ========================================= -->
<!-- ========================================= -->
<!-- Preliminary Experiments Section         -->
<!-- ========================================= -->

<!-- Slide A10: Preliminary Experiments Overview -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üß™ Preliminary Experiments Overview</h2>
  <div style="text-align: center; padding-top: 50px;">
    <ul class="textBlock" style="color: white; font-size: 1.2em;">
      <!-- Removed the "LunarLander‚Äëv2" bullet as requested -->
      <li class="fragment fade-in" style="margin-bottom: 10px;">‚öôÔ∏è Tested window-slide sizes: 16, 32, 64 for trade-offs in cost vs. accuracy.</li>
      <li class="fragment fade-in" style="margin-bottom: 10px;">üéØ Compared horizon sets {1,2,3,4,5} vs. {1,2,4,6,8} vs. fixed 8-step horizon.</li>
    </ul>
  </div>
</section>

<!-- Slide A11: Window-Slide Selection -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üìä Window-Slide Selection</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/WindowSlide_TrainLoss-1.jpg" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      ‚úÖ Slide=64 yields lowest training loss.
    </div>
  </div>
</section>

<!-- Slide A12: Adaptive Horizon Selection -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üéØ Adaptive Horizon Selection</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <!-- You can keep the original image if desired or update it -->
    <img src="img/Lunarlander_Horizon_Comparison-1.jpg" width="60%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      üéØ Adaptive Horizon Selection Result.
    </div>
  </div>
</section>

<!-- New Slide: Adaptive vs. Fixed Prediction Horizon Comparison -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üìä Adaptive vs. Fixed Horizon</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <!-- Updated image for comparison -->
    <img src="img/Lunarlander_Fixed_vs_Entropy.jpg" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      Adaptive {1,2,4,6,8} vs. fixed 8-step Prediction horizon.
    </div>
  </div>
</section>


<!-- Slide A13: Training Results: LunarLander -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">‚è± Training Results: LunarLander</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/TrainingReturn_LunderLander-1.jpg" width="60%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      ‚è± Full convergence reached in ~500k episodes.
    </div>
  </div>
</section>

<!-- Slide A14: Training Results: LiteSocNavGym -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">‚è± Training Results: LiteSocNavGym</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/TrainingReturn_SocNavGym-1.jpg" width="60%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      ‚è± Full convergence reached in ~4 Million episodes.
    </div>
  </div>
</section>

<!-- Slide A15: LunarLander Results (1) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 10px;">
    üìä LunarLander Results (1)
  </h2>
  <p style="color: white; text-align: center; font-size: 0.9em; margin-bottom: 20px;">
    Note: Gaussian noise (œÉ = 0.085) added to the environment only during testing.
  </p>
  <div style="text-align: center; padding-top: 20px; min-height: 300px;">
    <img src="img/lunarlander_results_part1.JPG" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      üìä Adaptive horizon SAC + CGLSTM achieves 175.22 average return.
    </div>
  </div>
</section>


<!-- Slide A16: LunarLander Results (2) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üìä LunarLander Results (2)</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/lunarlander_results_part2.JPG" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      üìä Highest weighted success for adaptive horizon: 99.73%.
    </div>
  </div>
</section>

<!-- Slide A17: LiteSocNavGym Results (1) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üìä LiteSocNavGym Results (1)</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/socnav_results_part1.JPG" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      üìä DreamerV3 + CGLSTM achieves 96% success.
    </div>
  </div>
</section>

<!-- Slide A18: LiteSocNavGym Results (2) -->
<section data-background="img/aston_slides_background_22.png" data-background-position="0 -20px">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üìä LiteSocNavGym Results (2)</h2>
  <div style="text-align: center; padding-top: 40px; min-height: 300px;">
    <img src="img/socnav_results_part2.JPG" width="70%" style="display: block; margin: 0 auto;">
    <div style="margin-top: 20px; color: white; text-align: center; font-size: 1.2em;">
      üìä Adaptive horizon yields balanced success &amp; cost.
    </div>
  </div>
</section>




<!-- ========================================= -->
<!-- CONCLUSION SLIDE (Bullet Points Only)    -->
<!-- ========================================= -->
<section data-background="img/aston_slides_background_22.png">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üéâ Conclusion</h2>
  <div style="text-align: center; color: white; padding-top: 20px;">
    <ul style="font-size: 1em; list-style: none; padding-left: 0;">
      <li class="fragment" style="margin-bottom: 10px;">
        üîç <strong>Novel Predictive Models</strong>: 2StepAhead, MASPM, and CGLSTM address short-horizon and reactive limitations in social robot navigation.
      </li>
      <li class="fragment" style="margin-bottom: 10px;">
        ‚úÖ <strong>Enhanced Performance</strong>: Demonstrated higher safety, human comfort, and success rates in diverse simulation environments.
      </li>
      <li class="fragment" style="margin-bottom: 10px;">
        üöÄ <strong>Adaptive Horizons in RL</strong>: Introduced an entropy‚Äêdriven approach that surpasses fixed-horizon methods and enhances continuous-control capabilities.
      </li>
    </ul>
  </div>
</section>

<!-- ========================================= -->
<!-- FUTURE WORK SLIDE (Image + Very Short Text) -->
<!-- ========================================= -->
<section data-background="img/aston_slides_background_22.png">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üöÄ Future Work</h2>
  <div style="text-align: center; color: white; padding-top: 20px;">
    <!-- Reduced Future Work Image -->
    <div style="margin-top: 20px;">
      <img 
        src="img/futureWork.jpg" 
        alt="Future Work Robot Platform" 
        style="width: 15%; border: 2px solid white; border-radius: 5px;"
      />
    </div>
    <!-- Very Short Text under the image -->
    <p style="font-size: 1.1em; max-width: 80%; margin: 20px auto 0; text-align: center;">
      Deploy RL models on a real robot via custom HAL.
    </p>
  </div>
</section>


<!-- ========================================= -->
<!-- PUBLICATIONS ARISING FROM THIS THESIS    -->
<!-- ========================================= -->
<section data-background="img/aston_slides_background_22.png">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">
        Publications Arising from this Thesis

  </h2>
  <div style="text-align: left; color: white; padding: 40px; font-size: 1em; max-width: 80%; margin: 0 auto;">
    <ul style="list-style-type: disc; padding-left: 20px;">
      <li class="fragment" style="margin-bottom: 10px;">
        üéØ Oguzie, Goodluck, e Anik√≥ Ek√°rt (2023). <strong>"Predictive World Models for Social Navigation."</strong> In: Advances in Computational Intelligence Systems, Contributi Presentati al 22¬∞ UK Workshop on Computational Intelligence (UKCI). Advances in Intelligent Systems and Computing (AISC). Springer. (In stampa)
      </li>
      <li class="fragment" style="margin-bottom: 10px;">
        üîç Oguzie, Goodluck. <strong>"Cosine-Gated LSTM."</strong> In: 2024 IEEE 5¬™ Conferenza Internazionale su Pattern Recognition e Machine Learning (PRML), pp. 8‚Äì15. IEEE, 2024.
      </li>
      <li class="fragment" style="margin-bottom: 10px;">
        üöÄ Oguzie, Goodluck. <strong>"Adaptive Prediction Horizons in RL."</strong> (In arrivo).
      </li>
    </ul>
  </div>
</section>

<!-- ========================================= -->
<!-- REFERENCES SLIDE 1 (References 1‚Äì8)       -->
<!-- ========================================= -->
<section data-background="img/aston_slides_background_22.png">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üìö References (1‚Äì8)</h2>
  <div style="text-align: left; color: white; padding: 30px; font-size: 0.85em; line-height: 1.3; max-width: 80%; margin: 0 auto;">
    <ol style="padding-left: 20px; margin: 0;">
      <li>R. C. Arkin, <em>Behavior-Based Robotics</em>. MIT Press, 1998.</li>
      <li>D. Helbing and P. Molnar, ‚ÄúSocial force model for pedestrian dynamics,‚Äù <em>Phys. Rev. E</em>, vol. 51, no. 5, p. 4282, 1995.</li>
      <li>J. van den Berg, S. J. Guy, M. Lin, and D. Manocha, ‚ÄúReciprocal n-body collision avoidance,‚Äù in <em>Robotics Research</em>. Springer, 2011.</li>
      <li>V. Mnih, K. Kavukcuoglu, D. Silver, et al., ‚ÄúPlaying Atari with deep reinforcement learning,‚Äù <em>arXiv preprint arXiv:1312.5602</em>, 2013.</li>
      <li>R. S. Sutton and A. G. Barto, <em>Reinforcement Learning: An Introduction</em>, 2nd ed. MIT Press, 2018.</li>
      <li>T. P. Lillicrap, J. Hunt, A. Pritzel, et al., ‚ÄúContinuous control with deep reinforcement learning,‚Äù <em>arXiv preprint arXiv:1509.02971</em>, 2015.</li>
      <li>J. Schulman, F. Wolski, P. Dhariwal, et al., ‚ÄúProximal policy optimization algorithms,‚Äù <em>arXiv preprint arXiv:1707.06347</em>, 2017.</li>
      <li>S. Fujimoto, H. van Hoof, and D. Meger, ‚ÄúAddressing function approximation error in actor-critic methods,‚Äù in <em>Proc. 35th Int. Conf. Machine Learning (ICML)</em>, 2018.</li>
    </ol>
  </div>
</section>

<!-- ========================================= -->
<!-- REFERENCES SLIDE 2 (References 9‚Äì15)      -->
<!-- ========================================= -->
<section data-background="img/aston_slides_background_22.png">
  <h2 style="color: white; text-align: center; margin-bottom: 20px;">üìö References (9‚Äì15)</h2>
  <div style="text-align: left; color: white; padding: 30px; font-size: 0.85em; line-height: 1.3; max-width: 80%; margin: 0 auto;">
    <ol style="padding-left: 20px; margin: 0;">
      <li>T. Haarnoja, A. Zhou, K. Hartikainen, et al., ‚ÄúSoft actor-critic algorithms and applications,‚Äù <em>arXiv preprint arXiv:1812.05905</em>, 2018.</li>
      <li>D. Hafner, T. Lillicrap, M. Norouzi, and J. Ba, ‚ÄúMastering diverse domains through world models,‚Äù <em>arXiv preprint arXiv:2301.04104</em>, 2023.</li>
      <li>D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ‚ÄúLearning representations by back-propagating errors,‚Äù <em>Nature</em>, vol. 323, pp. 533‚Äì536, 1986.</li>
      <li>S. Hochreiter and J. Schmidhuber, ‚ÄúLong short-term memory,‚Äù <em>Neural Computation</em>, vol. 9, no. 8, pp. 1735‚Äì1780, 1997.</li>
      <li>K. Cho, B. van Merrienboer, D. Bahdanau, and Y. Bengio, ‚ÄúOn the properties of neural machine translation: Encoder-decoder approaches,‚Äù <em>arXiv preprint arXiv:1409.1259</em>, 2014.</li>
      <li>A. Vaswani, N. Shazeer, N. Parmar, et al., ‚ÄúAttention is all you need,‚Äù in <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2017.</li>
      <li>D. Ha and J. Schmidhuber, ‚ÄúRecurrent world models facilitate policy evolution,‚Äù in <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2018.</li>
    </ol>
  </div>
</section>

<!-- ========================================= -->
<!-- THANK YOU / Q&A SLIDE (Viva Link Only)    -->
<!-- ========================================= -->
<section data-background="img/aston_slides_background_22.png">
  <h2 style="color: white; text-align: center; margin-top: 100px;">üôè Thank You</h2>
  <h4 style="color: white; text-align: center; margin-top: 30px;">Questions?</h4>
  <div style="text-align: center; margin-top: 30px;">
    <a href="https://goodluckoguzie.github.io/Viva" target="_blank" style="font-size: 1.2em; color: #00A9D4; text-decoration: none;">
      https://goodluckoguzie.github.io/Viva
    </a>
  </div>
</section>




    </div>
  </div>

  <script>
    Reveal.initialize({
      hash: true,
      width: 1600,
      height: 900,
      slideNumber: true,
      plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
    });

    // Handle fragment animations
    Reveal.addEventListener('fragmentshown', function(event) {
      event.fragment.classList.add('visible');
    });
    Reveal.addEventListener('fragmenthidden', function(event) {
      event.fragment.classList.remove('visible');
    });
  </script>
</body>
</html>
