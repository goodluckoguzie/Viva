<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>research - Goodluck Oguzie</title>
		<link rel="stylesheet" href="dist/reset.css" />
		<link rel="stylesheet" href="dist/reveal.css" />
		<link rel="stylesheet" href="dist/theme/white.css" />
		<link rel="stylesheet" href="plugin/highlight/monokai.css" />

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>

		<link rel="stylesheet" href="mycss.css" />

		<script type="text/javascript">
			window.addEventListener("load", function() {
			  var revealDiv = document.querySelector("body div.reveal");
			  var footer = document.querySelector(".footer");
			  revealDiv.appendChild(footer);
			});
		</script>

		<style>
			.reveal .slide-number {
				font-size: 24pt;
				color: #000000;
			}
			video::-webkit-media-controls-panel {
         		background-image: linear-gradient(transparent, transparent) !important;
    		}
			.reveal section div ul li span {
				line-height: 1.2;
			}
		</style>

	</head>
	<body>
		
		<div class="reveal">
			<div class="slides">
				<!-- =========== TITLE SLIDE (UPDATED BACKGROUND) =========== -->
				<section data-background="img/aston_title_background.jpg" data-background-size="cover" data-background-position="0 20px" style="color: white;">
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 1em;">
						  Enhancing Robot Social Navigation with<br>
						  Reinforcement Learning and Advanced <br>
						        Predictive Models
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						  Goodluck Oguzie
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						  190212683@aston.ac.uk
					</div>
				</section>

				<!-- =========== CONTENT SLIDE (UPDATED, CENTERED, WHITE TEXT, NUMBERED, FIXED BACKGROUND) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="top" data-transition="slide">
					<h2 style="color: white; text-align: center;">Content</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ol style="list-style-position: inside;">
							<li class="fragment">Context and Scope<br><span style="font-size: 0.75em;">Intro, goals</span></li>
							<li class="fragment">Social Robot Navigation<br><span style="font-size: 0.75em;">Overview, history, approaches</span></li>
							<li class="fragment">Reinforcement Learning<br><span style="font-size: 0.75em;">Core concepts, algorithms</span></li>
							<li class="fragment">Environments Used in This Research<br><span style="font-size: 0.75em;">SocNavGym, FallingBallEnv, LunarLander</span></li>
							<li class="fragment">Predictive World Models for Social Navigation<br><span style="font-size: 0.75em;">Challenges, methods, evaluation, results</span></li>
							<li class="fragment">Cosine-Gated LSTM (CGLSTM) for Prediction<br><span style="font-size: 0.75em;">Challenges, methods, evaluation, results</span></li>
							<li class="fragment">Adaptive Prediction Horizons in RL<br><span style="font-size: 0.75em;">Challenges, methods, evaluation, results</span></li>
							<li class="fragment">Conclusion<br><span style="font-size: 0.75em;">Summary, future work</span></li>
						</ol>
					</div>
					<aside class="notes">
						Outline the structure of your presentation: context, social navigation, RL fundamentals, environments, detailed contributions (predictive models, CGLSTM, adaptive horizons), and conclusion.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 3 - WHAT IS SOCIAL ROBOT NAVIGATION? (UPDATED BACKGROUND) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">What is Social Robot Navigation?</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Definition: Robots navigating safely in human-populated environments, respecting social norms.</li>
							<li class="fragment">Importance: Critical for seamless integration into daily life, ensuring safety and social acceptance.</li>
							<li class="fragment">Applications: Healthcare robots, hospitality robots, public space navigation.</li>
						</ul>
						<div class="fragment" style="padding-top: 20px;">
							<video muted data-autoplay src="img/socialrobot.mp4" width="70%" controls="controls"></video>
						</div>
					</div>
					<aside class="notes">
						Explain what social robot navigation means, its importance for real-world applications, and how the video illustrates robots interacting with humans.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 4 - CURRENT APPROACHES (UPDATED WITH CLASSICAL.PNG ON RIGHT) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">Current Approaches</h2>
					<div style="display: flex; justify-content: center; align-items: flex-start; padding-top: 100px;">
						<div style="flex: 0 0 50%; text-align: left; font-size: 0.85em; color: white; padding-right: 20px;">
							<ul>
								<li class="fragment">Traditional Methods:
									<ul style="list-style-type: none;">
										<li>Path planning (e.g., A*, Dijkstra’s) for static environments.</li>
										<li>Rule-based systems for human interaction.</li>
									</ul>
								</li>
								<li class="fragment">Modern Approaches:
									<ul style="list-style-type: none;">
										<li>Reinforcement Learning (RL), including advanced methods like Deep RL (e.g., DQN, policy gradient methods) for dynamic environments.</li>
									</ul>
								</li>
							</ul>
						</div>
						<div class="fragment" style="flex: 0 0 50%; text-align: center;">
							<img src="img/classical.PNG" width="100%" style="border: 2px solid white; max-width: 100%; height: auto;" />
						</div>
					</div>
					<aside class="notes">
						Discuss how traditional methods like path planning and rule-based systems work well in static environments but struggle with dynamic, human-populated settings. Highlight modern approaches, particularly RL, as a solution, setting the stage for your research. Mention the image as a visual aid for path planning or navigation methods.
					</aside>
				</section>

				<!-- =========== FOUNDATIONS: SLIDE 5 - SOCIAL ROBOT NAVIGATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Social Robot Navigation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Introduction: Robots navigating in human-populated environments, respecting social norms (Chapter 4, p. 58).</li>
							<li class="fragment">Historical Overview: Evolved from classical path planning to ML-based methods (Chapter 4, p. 58).</li>
							<li class="fragment">Approaches:
								<ul style="list-style-type: none;">
									<li>Classical: Path planning (A*, Dijkstra’s), rule-based systems (Chapter 4, p. 60).</li>
									<li>Machine Learning: RL, predictive models for dynamic settings (Chapter 4, p. 61).</li>
								</ul>
							</li>
							<li class="fragment">SocNavGym: A benchmark environment for testing social navigation (Chapter 4, p. 63).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/social_navigation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Introduce social robot navigation, its history, approaches, and SocNavGym, referencing the diagram illustrating classical vs. ML approaches or SocNavGym layout.
					</aside>
				</section>

				<!-- =========== FOUNDATIONS: SLIDE 6 - REINFORCEMENT LEARNING =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Reinforcement Learning</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Overview: RL enables robots to learn optimal navigation strategies via trial and error, maximizing rewards (Chapter 3, p. 34).</li>
							<li class="fragment">Key Concepts:
								<ul style="list-style-type: none;">
									<li>History: Originated in the 1950s, evolved with dynamic programming (Chapter 3, p. 32).</li>
									<li>RL Problem: Agent learns through trial and error (Chapter 3, p. 34).</li>
									<li>Model-Free (e.g., Q-learning, SAC): Learn from experience (Chapter 3, p. 36).</li>
									<li>Model-Based (e.g., DreamerV3): Use world models (Chapter 3, p. 36).</li>
									<li>Policy Learning: Optimize policies for actions (Chapter 3, p. 39).</li>
								</ul>
							</li>
							<li class="fragment">Algorithms Used: DQN, DDPG, PPO, A2C, SAC, DreamerV3 for social navigation (Chapter 3, p. 40–51).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/rl_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain RL’s core concepts, history, problem, model-free vs. model-based approaches, policy learning, and algorithms, emphasizing their application in social navigation, referencing the diagram illustrating RL frameworks or SocNavGym integration.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 7 - ENVIRONMENTS USED IN THIS RESEARCH =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Environments Used in This Research</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">SocNavGym: Benchmark for social navigation, testing RL and predictive models in dynamic, human-populated scenarios (Chapter 4, p. 63; Chapter 7, p. 132).</li>
							<li class="fragment">FallingBallEnv: Synthetic environment for sequence prediction, evaluating CGLSTM performance (Chapter 6, p. 103; Chapter 7, p. 132).</li>
							<li class="fragment">LunarLander-v2: Continuous control task for RL, assessing robustness and efficiency (Chapter 7, p. 132; Chapter 8, p. 150).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/environments_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe SocNavGym, FallingBallEnv, and LunarLander-v2, their roles in evaluating your RL and predictive models, and how the diagram illustrates these environments or their setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 8 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models: Challenges/Limitations</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Fixed Prediction Horizons: 2StepAhead and MASPM limited by inflexibility in dynamic environments, reducing adaptability (Chapter 5, p. 86).</li>
							<li class="fragment">Computational Overhead: MASPM’s multi-agent prediction increases processing demands, impacting efficiency (Chapter 5, p. 84).</li>
							<li class="fragment">Sparse Data: Difficulty predicting human behavior in SocNavGym due to limited training data, affecting accuracy (Chapter 5, p. 87).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of predictive world models, emphasizing fixed horizons, computational overhead, and sparse data issues, referencing the diagram illustrating these in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 9 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models: Methods</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">2StepAhead: Fixed two-step horizon model predicting short-term states for RL integration (Chapter 5, p. 83).</li>
							<li class="fragment">MASPM: Multi-action state prediction model for human-robot interactions, using RL state transitions (Chapter 5, p. 84).</li>
							<li class="fragment">2StepAhead-MASPM: Combined approach enhancing prediction accuracy in SocNavGym (Chapter 5, p. 85).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the methods of 2StepAhead, MASPM, and their combination, referencing the diagram illustrating their integration with RL in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 10 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models: Evaluation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, focusing on dynamic human-robot interactions (Chapter 5, p. 86).</li>
							<li class="fragment">Metrics: Training phase evaluated with MSE, testing phase with MAE and accuracy (Chapter 5, p. 87–88).</li>
							<li class="fragment">Approach: Compared 2StepAhead, MASPM, and 2StepAhead-MASPM for prediction robustness (Chapter 5, p. 86).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of predictive world models in SocNavGym, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 11 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models: Results</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Training Phase: 2StepAhead-MASPM achieved 20% lower MSE than standalone models, improving prediction stability (Chapter 5, p. 87).</li>
							<li class="fragment">Testing Phase: 2StepAhead-MASPM reduced MAE by 15% in SocNavGym, enhancing RL decision-making (Chapter 5, p. 88).</li>
							<li class="fragment">Impact: Improved RL robustness, but limited by fixed horizons (Chapter 5, p. 86).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the results of predictive world models, emphasizing 2StepAhead-MASPM performance and fixed horizon limitations, referencing the diagram showing MSE/MAE improvements in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 12 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">CGLSTM: Challenges/Limitations</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Prediction Accuracy: Traditional LSTMs, GRUs, and RAUs struggle with long-term sequence prediction in dynamic environments (Chapter 6, p. 94).</li>
							<li class="fragment">Sparse Data: Limited training data in SocNavGym affects CGLSTM performance, reducing generalization (Chapter 6, p. 113).</li>
							<li class="fragment">Computational Complexity: Higher processing demands for cosine gating compared to baseline models (Chapter 6, p. 98).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of CGLSTM, emphasizing prediction accuracy, sparse data, and computational complexity, referencing the diagram illustrating these in SocNavGym or FallingBallEnv.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 13 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">CGLSTM: Methods</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Architecture: Integrated cosine similarity-based gating into LSTM, enhancing long-term dependency modeling (Chapter 6, p. 96).</li>
							<li class="fragment">Training: Utilized backpropagation through time (BPTT) in SocNavGym and FallingBallEnv, optimizing for sequence prediction (Chapter 6, p. 98).</li>
							<li class="fragment">Integration: Combined with DreamerV3 and SAC for RL enhancement (Chapter 6, p. 114; Chapter 5, p. 124).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the CGLSTM architecture, training process, and integration with RL, referencing the diagram showing its structure or integration in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 14 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">CGLSTM: Evaluation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, FallingBallEnv, and additional tasks (e.g., Adding Problem, Row-wise MNIST) (Chapter 6, p. 103–114).</li>
							<li class="fragment">Metrics: Evaluated with Mean Absolute Error (MAE), Mean Squared Error (MSE), and accuracy (Chapter 6, p. 103).</li>
							<li class="fragment">Comparison: Compared against LSTM, GRU, and RAU for sequence prediction performance (Chapter 6, p. 103).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of CGLSTM across environments, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 15 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">CGLSTM: Results</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">FallingBallEnv: 30% MAE reduction compared to LSTM, GRU, and RAU (Chapter 6, p. 103).</li>
							<li class="fragment">SocNavGym: Improved sequence prediction, enhancing RL decision-making by 5% in cumulative rewards (Chapter 6, p. 113–114).</li>
							<li class="fragment">Additional Tasks: Outperformed baselines in Adding Problem, MNIST, FashionMNIST, IMDB, and Penn Treebank (Chapter 6, p. 108–111).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight CGLSTM results, emphasizing MAE reduction and reward improvements, referencing the diagram showing performance graphs or comparisons in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 16 - ADAPTIVE PREDICTION HORIZONS IN RL: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL: Challenges/Limitations</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Fixed Horizons: Current RL and predictive models (e.g., 2StepAhead) lack adaptability, reducing performance in dynamic environments (Chapter 7, p. 122).</li>
							<li class="fragment">Computational Cost: Entropy-based adaptation increases processing demands, potentially impacting real-time performance (Chapter 7, p. 125).</li>
							<li class="fragment">Exploration Uncertainty: Challenges in balancing exploration and exploitation in continuous action spaces (Chapter 7, p. 121).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of adaptive prediction horizons in RL, emphasizing fixed horizons, computational cost, and exploration uncertainty, referencing the diagram illustrating these in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 17 - ADAPTIVE PREDICTION HORIZONS IN RL: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL: Methods</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Entropy-Driven Adaptation: Dynamically adjusts prediction horizons based on policy entropy, enhancing RL adaptability (Chapter 7, p. 125).</li>
							<li class="fragment">Integration: Combined with CGLSTM and SAC, optimizing for continuous action spaces (Chapter 7, p. 124).</li>
							<li class="fragment">Framework: Proposed adaptive horizon selection using entropy measures, integrated into DreamerV3 for comparison (Chapter 7, p. 127–128).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the entropy-driven adaptive horizon methods in RL, integration with RL, and framework, referencing the diagram showing the mechanism or integration in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 18 - ADAPTIVE PREDICTION HORIZONS IN RL: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL: Evaluation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, FallingBallEnv, and LunarLander-v2, focusing on dynamic scenarios (Chapter 7, p. 132).</li>
							<li class="fragment">Metrics: Evaluated success rates, cumulative rewards, and inference time (Chapter 7, p. 136).</li>
							<li class="fragment">Comparison: Compared against fixed-horizon models (e.g., 2StepAhead) and baseline RL (SAC, DreamerV3) (Chapter 7, p. 138).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of adaptive prediction horizons in RL across environments, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 19 - ADAPTIVE PREDICTION HORIZONS IN RL: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL: Results</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">SocNavGym: 15% improvement in success rates in high-entropy scenarios, addressing adaptability limitations (Chapter 7, p. 138).</li>
							<li class="fragment">FallingBallEnv: Enhanced prediction accuracy, reducing MAE by 10% with adaptive horizons (Chapter 7, p. 141).</li>
							<li class="fragment">LunarLander-v2: Improved cumulative rewards by 8%, maintaining 2% increase in inference time (Chapter 7, p. 141).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight adaptive prediction horizon results in RL, emphasizing success rate improvements and efficiency, referencing the diagram showing performance graphs or comparisons in SocNavGym.
					</aside>
				</section>

				<!-- =========== CONCLUSION AND FUTURE WORK: SLIDE 20 - CONCLUSION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Conclusion</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Contributions: Developed CGLSTM, adaptive prediction horizons, and integrated RL (SAC, DreamerV3, DQN, DDPG, PPO, A2C) to address sample efficiency, fixed horizons, and exploration challenges (Chapter 8, p. 147–149).</li>
							<li class="fragment">Impact: Improved success rates, efficiency, and social compliance in SocNavGym, FallingBallEnv, and LunarLander-v2, overcoming current limitations (Chapter 8, p. 150–151).</li>
							<li class="fragment">Future Work: Extend to real-world deployment, address sensor noise, and explore broader applications like multi-robot systems (Chapter 8, p. 151–153).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/conclusion_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Summarize your thesis contributions, impact, and future directions, referencing the diagram illustrating contributions or future research paths, preparing for Q&A.
					</aside>
				</section>

				<!-- =========== PERSONAL: SLIDE 21 - ABOUT ME =========== -->
				<section data-background="img/aston_background.jpg" data-transition="slide">
					<h3>About Me</h3>
					<div style="text-align: left; font-size: 0.85em;">
						<ul>
							<li class="fragment">Goodluck Oguzie</li>
							<li class="fragment">PhD in Robotics, <a href="https://robolab.unex.es/">Universidad de Extremadura</a>, Cáceres, Spain
								<div class="fragment" style="text-align: center;">
									<img src="img/caceres.jpg" width="70%" style="border: 2px solid white;"/>
								</div>
							</li>
							<li class="fragment">PhD Focus: Robotics, Active Perception, POMDP & Particle Filters</li>
							<li class="fragment">Career: Joined Aston University in August 2018 as Lecturer, now Senior Lecturer</li>
							<li class="fragment">Lab: <a href="https://arp-lab.com">Autonomous Robotics and Perception Lab</a></li>
						</ul>
					</div>
					<aside class="notes">
						Highlight your journey from PhD to current role, and briefly mention how it ties to social navigation research.
					</aside>
				</section>

			</div>
		</div>

		<script>
			Reveal.initialize({
				hash: true,
				width: 1600,
				height: 900,
				slideNumber: true,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>

		<!-- <div class="footer">
			<span style="font-size: 0.7em;">https://ljmanso.github.io/r</span>
		</div> -->
	</body>
</html>
