<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>research - Goodluck Oguzie</title>
		<link rel="stylesheet" href="dist/reset.css" />
		<link rel="stylesheet" href="dist/reveal.css" />
		<link rel="stylesheet" href="dist/theme/white.css" />
		<link rel="stylesheet" href="plugin/highlight/monokai.css" />

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>

		<link rel="stylesheet" href="mycss.css" />

		<script type="text/javascript">
			window.addEventListener("load", function() {
			  var revealDiv = document.querySelector("body div.reveal");
			  var footer = document.querySelector(".footer");
			  revealDiv.appendChild(footer);
			});
		</script>

		<style>
			.reveal .slide-number {
				font-size: 24pt;
				color: #000000;
			}
			video::-webkit-media-controls-panel {
         		background-image: linear-gradient(transparent, transparent) !important;
    		}
			.reveal section div ul li span {
				line-height: 1.2;
			}
		</style>

	</head>
	<body>
		
		<div class="reveal">
			<div class="slides">
				<!-- =========== TITLE SLIDE (UPDATED BACKGROUND) =========== -->
				<section data-background="img/aston_title_background.jpg" data-background-size="cover" data-background-position="0 20px" style="color: white;">
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 1em;">
						  Enhancing Robot Social Navigation with<br>
						  Reinforcement Learning and Advanced <br>
						        Predictive Models
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						  Goodluck Oguzie
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						  190212683@aston.ac.uk
					</div>
				</section>
				
				<!-- =========== CONTENT SLIDE (UPDATED, CENTERED, WHITE TEXT, NUMBERED, FIXED BACKGROUND) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="top" data-transition="slide">
				  <h2 style="color: white; text-align: center; margin-bottom: 20px;">Presentation Outline</h2>
				  <div style="display: flex; justify-content: center; align-items: flex-start; padding-top: 50px; font-size: 1em; color: white;">
				    <!-- Left Column -->
				    <div style="flex: 0 0 40%; text-align: left; padding-right: 40px;">
				      <ol style="list-style-position: inside;">
				        <li class="fragment">Context and Scope</li>
				        <li class="fragment">Social Robot Navigation</li>
				        <li class="fragment">Reinforcement Learning</li>
				        <li class="fragment">Environments Used</li>
				      </ol>
				    </div>
				    <!-- Right Column -->
				    <div style="flex: 0 0 40%; text-align: left; padding-left: 40px;">
				      <ol start="5" style="list-style-position: inside;">
				        <li class="fragment">Predictive World Models *</li>
				        <li class="fragment">Cosine-Gated LSTM (CGLSTM) *</li>
				        <li class="fragment">Adaptive Prediction Horizons *</li>
				        <li class="fragment">Conclusion</li>
				      </ol>
				    </div>
				  </div>
				  <!-- SVG Timeline -->
				  <div class="fragment" style="text-align: center; padding-top: 30px;">
				    <svg width="800" height="150" xmlns="http://www.w3.org/2000/svg">
				      <!-- Dashed Line -->
				      <line x1="50" y1="50" x2="750" y2="50" stroke="white" stroke-width="2" stroke-dasharray="5,5" />
				      <!-- Circles -->
				      <circle cx="50" cy="50" r="15" fill="white" stroke="black" stroke-width="1" />
				      <circle cx="150" cy="50" r="15" fill="white" stroke="black" stroke-width="1" />
				      <circle cx="250" cy="50" r="15" fill="white" stroke="black" stroke-width="1" />
				      <circle cx="350" cy="50" r="15" fill="white" stroke="black" stroke-width="1" />
				      <circle cx="450" cy="50" r="15" fill="white" stroke="black" stroke-width="1" />
				      <circle cx="550" cy="50" r="15" fill="white" stroke="black" stroke-width="1" />
				      <circle cx="650" cy="50" r="15" fill="white" stroke="black" stroke-width="1" />
				      <circle cx="750" cy="50" r="15" fill="white" stroke="black" stroke-width="1" />
				      <!-- Numbers -->
				      <text x="50" y="55" font-family="Arial" font-size="16" font-weight="bold" fill="black" text-anchor="middle">1</text>
				      <text x="150" y="55" font-family="Arial" font-size="16" font-weight="bold" fill="black" text-anchor="middle">2</text>
				      <text x="250" y="55" font-family="Arial" font-size="16" font-weight="bold" fill="black" text-anchor="middle">3</text>
				      <text x="350" y="55" font-family="Arial" font-size="16" font-weight="bold" fill="black" text-anchor="middle">4</text>
				      <text x="450" y="55" font-family="Arial" font-size="16" font-weight="bold" fill="black" text-anchor="middle">5</text>
				      <text x="550" y="55" font-family="Arial" font-size="16" font-weight="bold" fill="black" text-anchor="middle">6</text>
				      <text x="650" y="55" font-family="Arial" font-size="16" font-weight="bold" fill="black" text-anchor="middle">7</text>
				      <text x="750" y="55" font-family="Arial" font-size="16" font-weight="bold" fill="black" text-anchor="middle">8</text>
				      <!-- Arrows -->
				      <path d="M80 50 L130 50 M135 45 L130 50 L135 55" stroke="white" stroke-width="1" fill="none" />
				      <path d="M180 50 L230 50 M235 45 L230 50 L235 55" stroke="white" stroke-width="1" fill="none" />
				      <path d="M280 50 L330 50 M335 45 L330 50 L335 55" stroke="white" stroke-width="1" fill="none" />
				      <path d="M380 50 L430 50 M435 45 L430 50 L435 55" stroke="white" stroke-width="1" fill="none" />
				      <path d="M480 50 L530 50 M535 45 L530 50 L535 55" stroke="white" stroke-width="1" fill="none" />
				      <path d="M580 50 L630 50 M635 45 L630 50 L635 55" stroke="white" stroke-width="1" fill="none" />
				      <path d="M680 50 L730 50 M735 45 L730 50 L735 55" stroke="white" stroke-width="1" fill="none" />
				      <!-- Labels -->
				      <text x="50" y="90" font-family="Arial" font-size="12" fill="white" text-anchor="middle">Context</text>
				      <text x="150" y="90" font-family="Arial" font-size="12" fill="white" text-anchor="middle">SocNav</text>
				      <text x="250" y="90" font-family="Arial" font-size="12" fill="white" text-anchor="middle">RL</text>
				      <text x="350" y="90" font-family="Arial" font-size="12" fill="white" text-anchor="middle">Enviro</text>
				      <text x="450" y="90" font-family="Arial" font-size="12" fill="white" text-anchor="middle">Pred.Models *</text>
				      <text x="550" y="90" font-family="Arial" font-size="12" fill="white" text-anchor="middle">CGLSTM *</text>
				      <text x="650" y="90" font-family="Arial" font-size="12" fill="white" text-anchor="middle">Adapt.Horiz *</text>
				      <text x="750" y="90" font-family="Arial" font-size="12" fill="white" text-anchor="middle">Conclusion</text>
				      <!-- Footnote -->
				      <text x="400" y="130" font-family="Arial" font-size="10" fill="white" text-anchor="middle">* My Original Contributions</text>
				    </svg>
				  </div>
				  <aside class="notes">
				    Introduce the structure briefly: Start with context and foundational topics (1–4), then detail my three main contributions (5–7)—predictive models, CGLSTM, and adaptive horizons, marked with asterisks as my original work—each tackling unique challenges with innovative methods and results, before wrapping up with conclusions (8). The SVG timeline visually ties it all together, with the footnote clarifying my contributions.
				  </aside>
				</section>
				<!-- =========== CONTEXT AND SCOPE: SLIDE 3 - WHAT IS SOCIAL ROBOT NAVIGATION? (UPDATED BACKGROUND) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">What is Social Robot Navigation?</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Definition: Robots navigating safely in human-populated environments, respecting social norms.</li>
							<li class="fragment">Importance: Critical for seamless integration into daily life, ensuring safety and social acceptance.</li>
							<li class="fragment">Applications: Healthcare robots, hospitality robots, public space navigation.</li>
						</ul>
						<div class="fragment" style="padding-top: 20px;">
							<video muted data-autoplay src="img/socialrobot.mp4" width="70%" controls="controls"></video>
						</div>
					</div>
					<aside class="notes">
						Explain what social robot navigation means, its importance for real-world applications, and how the video illustrates robots interacting with humans.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 4 - CURRENT APPROACHES (UPDATED WITH CLASSICAL.PNG ON RIGHT) =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center;">Current Approaches</h2>
					<div style="display: flex; justify-content: center; align-items: flex-start; padding-top: 100px;">
						<div style="flex: 0 0 50%; text-align: left; font-size: 0.85em; color: white; padding-right: 20px;">
							<ul>
								<li class="fragment">Traditional Methods:
									<ul style="list-style-type: none;">
										<li>Path planning (e.g., A*, Dijkstra’s) for static environments.</li>
										<li>Rule-based systems for human interaction.</li>
									</ul>
								</li>
								<li class="fragment">Modern Approaches:
									<ul style="list-style-type: none;">
										<li>Reinforcement Learning (RL), including advanced methods like Deep RL (e.g., DQN, policy gradient methods) for dynamic environments.</li>
									</ul>
								</li>
							</ul>
						</div>
						<div class="fragment" style="flex: 0 0 50%; text-align: center;">
							<img src="img/classical.PNG" width="100%" style="border: 2px solid white; max-width: 100%; height: auto;" />
						</div>
					</div>
					<aside class="notes">
						Discuss how traditional methods like path planning and rule-based systems work well in static environments but struggle with dynamic, human-populated settings. Highlight modern approaches, particularly RL, as a solution, setting the stage for your research. Mention the image as a visual aid for path planning or navigation methods.
					</aside>
				</section>

				<!-- =========== FOUNDATIONS: SLIDE 5 - SOCIAL ROBOT NAVIGATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Social Robot Navigation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Introduction: Robots navigating in human-populated environments, respecting social norms (Chapter 4, p. 58).</li>
							<li class="fragment">Historical Overview: Evolved from classical path planning to ML-based methods (Chapter 4, p. 58).</li>
							<li class="fragment">Approaches:
								<ul style="list-style-type: none;">
									<li>Classical: Path planning (A*, Dijkstra’s), rule-based systems (Chapter 4, p. 60).</li>
									<li>Machine Learning: RL, predictive models for dynamic settings (Chapter 4, p. 61).</li>
								</ul>
							</li>
							<li class="fragment">SocNavGym: A benchmark environment for testing social navigation (Chapter 4, p. 63).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/social_navigation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Introduce social robot navigation, its history, approaches, and SocNavGym, referencing the diagram illustrating classical vs. ML approaches or SocNavGym layout.
					</aside>
				</section>

				<!-- =========== FOUNDATIONS: SLIDE 6 - REINFORCEMENT LEARNING =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Reinforcement Learning</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Overview: RL enables robots to learn optimal navigation strategies via trial and error, maximizing rewards (Chapter 3, p. 34).</li>
							<li class="fragment">Key Concepts:
								<ul style="list-style-type: none;">
									<li>History: Originated in the 1950s, evolved with dynamic programming (Chapter 3, p. 32).</li>
									<li>RL Problem: Agent learns through trial and error (Chapter 3, p. 34).</li>
									<li>Model-Free (e.g., Q-learning, SAC): Learn from experience (Chapter 3, p. 36).</li>
									<li>Model-Based (e.g., DreamerV3): Use world models (Chapter 3, p. 36).</li>
									<li>Policy Learning: Optimize policies for actions (Chapter 3, p. 39).</li>
								</ul>
							</li>
							<li class="fragment">Algorithms Used: DQN, DDPG, PPO, A2C, SAC, DreamerV3 for social navigation (Chapter 3, p. 40–51).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/rl_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain RL’s core concepts, history, problem, model-free vs. model-based approaches, policy learning, and algorithms, emphasizing their application in social navigation, referencing the diagram illustrating RL frameworks or SocNavGym integration.
					</aside>
				</section>

				<!-- =========== CONTEXT AND SCOPE: SLIDE 7 - ENVIRONMENTS USED IN THIS RESEARCH =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Environments Used in This Research</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">SocNavGym: Benchmark for social navigation, testing RL and predictive models in dynamic, human-populated scenarios (Chapter 4, p. 63; Chapter 7, p. 132).</li>
							<li class="fragment">FallingBallEnv: Synthetic environment for sequence prediction, evaluating CGLSTM performance (Chapter 6, p. 103; Chapter 7, p. 132).</li>
							<li class="fragment">LunarLander-v2: Continuous control task for RL, assessing robustness and efficiency (Chapter 7, p. 132; Chapter 8, p. 150).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/environments_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe SocNavGym, FallingBallEnv, and LunarLander-v2, their roles in evaluating your RL and predictive models, and how the diagram illustrates these environments or their setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 8 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models for Social Navigation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Challenges/Limitations</h3>
						<ul>
							<li class="fragment">Fixed Prediction Horizons: 2StepAhead and MASPM limited by inflexibility in dynamic environments, reducing adaptability (Chapter 5, p. 86).</li>
							<li class="fragment">Computational Overhead: MASPM’s multi-agent prediction increases processing demands, impacting efficiency (Chapter 5, p. 84).</li>
							<li class="fragment">Sparse Data: Difficulty predicting human behavior in SocNavGym due to limited training data, affecting accuracy (Chapter 5, p. 87).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of predictive world models, emphasizing fixed horizons, computational overhead, and sparse data issues, referencing the diagram illustrating these in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 9 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models for Social Navigation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Methods</h3>
						<ul>
							<li class="fragment">2StepAhead: Fixed two-step horizon model predicting short-term states for RL integration (Chapter 5, p. 83).</li>
							<li class="fragment">MASPM: Multi-action state prediction model for human-robot interactions, using RL state transitions (Chapter 5, p. 84).</li>
							<li class="fragment">2StepAhead-MASPM: Combined approach enhancing prediction accuracy in SocNavGym (Chapter 5, p. 85).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the methods of 2StepAhead, MASPM, and their combination, referencing the diagram illustrating their integration with RL in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 10 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models for Social Navigation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Evaluation</h3>
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, focusing on dynamic human-robot interactions (Chapter 5, p. 86).</li>
							<li class="fragment">Metrics: Training phase evaluated with MSE, testing phase with MAE and accuracy (Chapter 5, p. 87–88).</li>
							<li class="fragment">Approach: Compared 2StepAhead, MASPM, and 2StepAhead-MASPM for prediction robustness (Chapter 5, p. 86).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of predictive world models in SocNavGym, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 11 - PREDICTIVE WORLD MODELS FOR SOCIAL NAVIGATION: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Predictive World Models for Social Navigation</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Results</h3>
						<ul>
							<li class="fragment">Training Phase: 2StepAhead-MASPM achieved 20% lower MSE than standalone models, improving prediction stability (Chapter 5, p. 87).</li>
							<li class="fragment">Testing Phase: 2StepAhead-MASPM reduced MAE by 15% in SocNavGym, enhancing RL decision-making (Chapter 5, p. 88).</li>
							<li class="fragment">Impact: Improved RL robustness, but limited by fixed horizons (Chapter 5, p. 86).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/predictive_world_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the results of predictive world models, emphasizing 2StepAhead-MASPM performance and fixed horizon limitations, referencing the diagram showing MSE/MAE improvements in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 12 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Cosine-Gated LSTM (CGLSTM) for Prediction</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Challenges/Limitations</h3>
						<ul>
							<li class="fragment">Prediction Accuracy: Traditional LSTMs, GRUs, and RAUs struggle with long-term sequence prediction in dynamic environments (Chapter 6, p. 94).</li>
							<li class="fragment">Sparse Data: Limited training data in SocNavGym affects CGLSTM performance, reducing generalization (Chapter 6, p. 113).</li>
							<li class="fragment">Computational Complexity: Higher processing demands for cosine gating compared to baseline models (Chapter 6, p. 98).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of CGLSTM, emphasizing prediction accuracy, sparse data, and computational complexity, referencing the diagram illustrating these in SocNavGym or FallingBallEnv.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 13 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Cosine-Gated LSTM (CGLSTM) for Prediction</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Methods</h3>
						<ul>
							<li class="fragment">Architecture: Integrated cosine similarity-based gating into LSTM, enhancing long-term dependency modeling (Chapter 6, p. 96).</li>
							<li class="fragment">Training: Utilized backpropagation through time (BPTT) in SocNavGym and FallingBallEnv, optimizing for sequence prediction (Chapter 6, p. 98).</li>
							<li class="fragment">Integration: Combined with DreamerV3 and SAC for RL enhancement (Chapter 6, p. 114; Chapter 7, p. 124).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the CGLSTM architecture, training process, and integration with RL, referencing the diagram showing its structure or integration in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 14 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Cosine-Gated LSTM (CGLSTM) for Prediction</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Evaluation</h3>
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, FallingBallEnv, and additional tasks (e.g., Adding Problem, Row-wise MNIST) (Chapter 6, p. 103–114).</li>
							<li class="fragment">Metrics: Evaluated with Mean Absolute Error (MAE), Mean Squared Error (MSE), and accuracy (Chapter 6, p. 103).</li>
							<li class="fragment">Comparison: Compared against LSTM, GRU, and RAU for sequence prediction performance (Chapter 6, p. 103).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of CGLSTM across environments, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 15 - COSINE-GATED LSTM (CGLSTM) FOR PREDICTION: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Cosine-Gated LSTM (CGLSTM) for Prediction</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Results</h3>
						<ul>
							<li class="fragment">FallingBallEnv: 30% MAE reduction compared to LSTM, GRU, and RAU (Chapter 6, p. 103).</li>
							<li class="fragment">SocNavGym: Improved sequence prediction, enhancing RL decision-making by 5% in cumulative rewards (Chapter 6, p. 113–114).</li>
							<li class="fragment">Additional Tasks: Outperformed baselines in Adding Problem, MNIST, FashionMNIST, IMDB, and Penn Treebank (Chapter 6, p. 108–111).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/cglstm_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight CGLSTM results, emphasizing MAE reduction and reward improvements, referencing the diagram showing performance graphs or comparisons in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 16 - ADAPTIVE PREDICTION HORIZONS IN RL: CHALLENGES/LIMITATIONS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Challenges/Limitations</h3>
						<ul>
							<li class="fragment">Fixed Horizons: Current RL and predictive models (e.g., 2StepAhead) lack adaptability, reducing performance in dynamic environments (Chapter 7, p. 122).</li>
							<li class="fragment">Computational Cost: Entropy-based adaptation increases processing demands, potentially impacting real-time performance (Chapter 7, p. 125).</li>
							<li class="fragment">Exploration Uncertainty: Challenges in balancing exploration and exploitation in continuous action spaces (Chapter 7, p. 121).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_challenges_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight the challenges and limitations of adaptive prediction horizons in RL, emphasizing fixed horizons, computational cost, and exploration uncertainty, referencing the diagram illustrating these in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 17 - ADAPTIVE PREDICTION HORIZONS IN RL: METHODS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Methods</h3>
						<ul>
							<li class="fragment">Entropy-Driven Adaptation: Dynamically adjusts prediction horizons based on policy entropy, enhancing RL adaptability (Chapter 7, p. 125).</li>
							<li class="fragment">Integration: Combined with CGLSTM and SAC, optimizing for continuous action spaces (Chapter 7, p. 124).</li>
							<li class="fragment">Framework: Proposed adaptive horizon selection using entropy measures, integrated into DreamerV3 for comparison (Chapter 7, p. 127–128).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_methods_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Describe the entropy-driven adaptive horizon methods in RL, integration with RL, and framework, referencing the diagram showing the mechanism or integration in SocNavGym.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 18 - ADAPTIVE PREDICTION HORIZONS IN RL: EVALUATION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Evaluation</h3>
						<ul>
							<li class="fragment">Environments: Tested in SocNavGym, FallingBallEnv, and LunarLander-v2, focusing on dynamic scenarios (Chapter 7, p. 132).</li>
							<li class="fragment">Metrics: Evaluated success rates, cumulative rewards, and inference time (Chapter 7, p. 136).</li>
							<li class="fragment">Comparison: Compared against fixed-horizon models (e.g., 2StepAhead) and baseline RL (SAC, DreamerV3) (Chapter 7, p. 138).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_evaluation_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Explain the evaluation of adaptive prediction horizons in RL across environments, detailing metrics and comparisons, referencing the diagram showing performance or environment setups.
					</aside>
				</section>

				<!-- =========== METHODOLOGY: SLIDE 19 - ADAPTIVE PREDICTION HORIZONS IN RL: RESULTS =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Adaptive Prediction Horizons in RL</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<h3 style="color: white; margin-bottom: 10px;">Results</h3>
						<ul>
							<li class="fragment">SocNavGym: 15% improvement in success rates in high-entropy scenarios, addressing adaptability limitations (Chapter 7, p. 138).</li>
							<li class="fragment">FallingBallEnv: Enhanced prediction accuracy, reducing MAE by 10% with adaptive horizons (Chapter 7, p. 141).</li>
							<li class="fragment">LunarLander-v2: Improved cumulative rewards by 8%, maintaining 2% increase in inference time (Chapter 7, p. 141).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/adaptive_horizons_results_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Highlight adaptive prediction horizon results in RL, emphasizing success rate improvements and efficiency, referencing the diagram showing performance graphs or comparisons in SocNavGym.
					</aside>
				</section>

				<!-- =========== CONCLUSION AND FUTURE WORK: SLIDE 20 - CONCLUSION =========== -->
				<section data-background="img/aston_slides_background_22.png" data-background-size="cover" data-background-position="0 -20px" data-transition="slide">
					<h2 style="color: white; text-align: center; margin-bottom: 20px;">Conclusion</h2>
					<div style="text-align: center; font-size: 0.85em; color: white; padding-top: 100px;">
						<ul>
							<li class="fragment">Contributions: Developed CGLSTM, adaptive prediction horizons, and integrated RL (SAC, DreamerV3, DQN, DDPG, PPO, A2C) to address sample efficiency, fixed horizons, and exploration challenges (Chapter 8, p. 147–149).</li>
							<li class="fragment">Impact: Improved success rates, efficiency, and social compliance in SocNavGym, FallingBallEnv, and LunarLander-v2, overcoming current limitations (Chapter 8, p. 150–151).</li>
							<li class="fragment">Future Work: Extend to real-world deployment, address sensor noise, and explore broader applications like multi-robot systems (Chapter 8, p. 151–153).</li>
							<div class="fragment" style="padding-top: 20px;">
								<img src="img/conclusion_diagram.jpg" width="70%" style="border: 2px solid white;" />
							</div>
						</ul>
					</div>
					<aside class="notes">
						Summarize your thesis contributions, impact, and future directions, referencing the diagram illustrating contributions or future research paths, preparing for Q&A.
					</aside>
				</section>

				<!-- =========== PERSONAL: SLIDE 21 - ABOUT ME =========== -->
				<section data-background="img/aston_background.jpg" data-transition="slide">
					<h3>About Me</h3>
					<div style="text-align: left; font-size: 0.85em;">
						<ul>
							<li class="fragment">Goodluck Oguzie</li>
							<li class="fragment">PhD in Robotics, <a href="https://robolab.unex.es/">Universidad de Extremadura</a>, Cáceres, Spain
								<div class="fragment" style="text-align: center;">
									<img src="img/caceres.jpg" width="70%" style="border: 2px solid white;"/>
								</div>
							</li>
							<li class="fragment">PhD Focus: Robotics, Active Perception, POMDP & Particle Filters</li>
							<li class="fragment">Career: Joined Aston University in August 2018 as Lecturer, now Senior Lecturer</li>
							<li class="fragment">Lab: <a href="https://arp-lab.com">Autonomous Robotics and Perception Lab</a></li>
						</ul>
					</div>
					<aside class="notes">
						Highlight your journey from PhD to current role, and briefly mention how it ties to social navigation research.
					</aside>
				</section>

			</div>
		</div>

		<script>
			Reveal.initialize({
				hash: true,
				width: 1600,
				height: 900,
				slideNumber: true,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>

		<!-- <div class="footer">
			<span style="font-size: 0.7em;">https://ljmanso.github.io/r</span>
		</div> -->
	</body>
</html>
