<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>research - Goodluck Oguzie</title>
		<link rel="stylesheet" href="dist/reset.css" />
		<link rel="stylesheet" href="dist/reveal.css" />
		<link rel="stylesheet" href="dist/theme/white.css" />
		<link rel="stylesheet" href="plugin/highlight/monokai.css" />

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>

		<link rel="stylesheet" href="mycss.css" />

		<script type="text/javascript">
			window.addEventListener("load", function() {
			  var revealDiv = document.querySelector("body div.reveal");
			  var footer = document.querySelector(".footer");
			  revealDiv.appendChild(footer);
			});
		</script>

		<style>
			.reveal .slide-number {
				font-size: 24pt;
				color: #000000;
			}

			video::-webkit-media-controls-panel {
         		background-image: linear-gradient(transparent, transparent) !important;
    		}
		</style>

	</head>
	<body>
		
		<div class="reveal">
			<div class="slides">
				<!-- =========== TITLE SLIDE =========== -->
				<section data-background="img/aston_title_background.jpg">
					<!-- Vertical spacing -->
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 1em;">&nbsp; &nbsp;</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 1em;">&nbsp; &nbsp;</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 1em;">&nbsp; &nbsp;</div>
					<!-- Title -->
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 1em;">
						&nbsp; &nbsp; Enhancing Robot Social Navigation with Reinforcement Learning and Advanced Predictive Models
					</div>
					<!-- New details block -->
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						&nbsp; &nbsp; Autonomous Robotics and Perception Laboratory - https://arp-lab.com
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						&nbsp; &nbsp; https://ljmanso.com
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						&nbsp; &nbsp; Goodluck Oguzie
					</div>
					<div style="text-align: left; margin: 0 auto; width: 100%; font-size: 0.9em;">
						&nbsp; &nbsp; 190212683@aston.ac.uk
					</div>
				</section>

				<section>
					<h2>Outline</h2>
					<ul>
						<li>A bit about me</li>
						<li>Lines of research</li>
						<li>Social robot navigation</li>
						<li>Hint at the future</li>
					</ul>
				</section>

				<section>
					<h3>About me</h3>
					<ul>
						<li>Goodluck Oguzie</li>
						<li>PhD in Robotics from <a href="https://robolab.unex.es/">Universidad de Extremadura</a> (C&aacute;ceres, Extremadura, Spain)
							<div class="fragment disappear" style="text-align: center;">
								<img src="img/caceres.jpg" width="90%"/>
							</div>
						</li>
						<li class="fragment">PhD topic: robotics, active perception, POMDP/PF</li>
						<li class="fragment">I joined Aston in August 2018 as a Lecturer in CS, later promoted to Senior Lecturer</li>
						<li class="fragment">Autonomous Robotics and Perception Laboratory <a href="https://arp-lab.com">https://arp-lab.com</a></li>
					</ul>
				</section>

				<section>
					<h2>Lines of research</h2>
					<ul>
						<li>human pose estimation <b>&amp;</b> monitoring</li>
						<li>monocular depth estimation <b>&amp;</b> traffic understanding</li>
						<li>social navigation</li>
					</ul>
				</section>

				<section>
					<section>
						<h4>Human tracking and monitoring</h4>
						<ul style="font-size: 0.8em; line-height: 1.1;">
							<li>Motivation: experience from previous projects <b>&amp;</b> the need for tracking in Social Robot Navigation</li>
							<li class="fragment">Applicable in real-life conditions</li>
							<li class="fragment">Multi-camera, multi-person, full-skeleton, self-supervised</li>
							<li class="fragment">Project with Legrand Care, Â£244,512 (January 2024, 30 months).</li>
							<li class="fragment">With PhD students D. Rodriguez-Criado (former), V. Gbouna and PDRA Maria Vicini.</li>
						</ul>
						<span class="fragment">
							<video muted data-autoplay id="video_hpe" src="resources/sevilla2.mp4" width="540px" controls="controls"></video>
							<video data-autoplay id="video_hpe" src="resources/hpe.mp4" width="630px" controls="controls"></video>
						</span>
						<br/>
						<div class="reveal" style="width: 70%; margin-left: auto; margin-right: auto; line-height: 1.06;">
							<span style="font-family: monospace; font-size: 0.45em; text-align: left; display: inline-block;">
								<b style="color: red;">[1]</b> Rodriguez-Criado D, Bachiller-Burgos P, Vogiatzis G, Manso LJ. Multi-person 3D pose estimation from unlabelled data.
								<u>Machine Vision and Applications, Springer</u>. 2024 May;35(3):1-8.
							</span>
						</div>
					</section>

					<section>
						<embed src="pdfs/hpe.pdf" width="90%" height="900px"/>
					</section>
				</section>

				<!-- Continue with remaining sections unchanged... -->

			</div>
		</div>

		<script>
			Reveal.initialize({
				hash: true,
				width: 1600,
				height: 900,
				slideNumber: true,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>

		<!-- <div class="footer">
			<span style="font-size: 0.7em;">https://ljmanso.github.io/r</span>
		</div> -->
	</body>
</html>
